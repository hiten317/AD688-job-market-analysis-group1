[
  {
    "objectID": "job_trends_analysis.html",
    "href": "job_trends_analysis.html",
    "title": "Quantitative Analysis of Business Analytics, Data Science and Machine Learning",
    "section": "",
    "text": "1 Introduction to Quantitative Analysis\nNow that we had a deep dive in qualtitative analysis of Machine Learning, Data Analyst and Data Scientist positions, we want to leverage the Lightcast job postings data from 2024 to verify whether the findings from the research align with the current data from the market. One of the consistent themes from the research was an overlap between Machine Learning and Data Science positions because of skillsets required for these experienced roles. We will also explore if Business analyst/Data analyst positions have few most in-demand skillsets and what are they as these are foundational roles in data.\n\n\n2 Methodology\nThe first step would be to clean the dataset and identify the most relevant columns. Subset the data for Machine Learning, BA/DA and Data scientist positions data so these can be processed in silos Peform EDA for each role and highlight patterns or trends Perform Random Forest algorithms to predict salaries for these positions Summarise the findings\n\n\n3 Data Cleaning and Preprocessing\nML specific positions are limited in title clean - Since we cannot seem to distinguish the data between Data Science and Machine Learning, from the dataset using job titles, we will focus on Data Scientist and Business Analyst positions. Qualitative data also suggested a strong overlap between Data Science and Machine Learning positions because the current job market expects candidates for Data scientist positions to have skills in not just ML models but production deployment and Artificial intelligence as well. (Nobrega, 2024)\nSummarizing the cleaning of data for both positions: The most important data cleaning steps performed here were slicing the data for each position to process them individually. Location column was separated into Latitude and Logitude to enable geographic analysis of job postings. Remote type, education levels and employment type columns were converted into categories to visualized summarized data. Skillsets columns will be cleaned at a later stage when we analyze top skills for each position and then progress into Machine Learning.\n\n\n4 Geographical analysis of Business Analytics, Data Science and Machine Learning\n\n\n\nAnalysis - Our first step in laying our career path is to narrow down the geographical locations where the positions are frequently available, so we have better chance of landing a job. Higher the number of positions available in a location, higher the chances of landing a job even though the competition is high, the odds of receiving an offer remain optimistic. The above plot is an hvplot providing a side by side comparison of top 10 states in the US for Business Analyst/Data Analyst and Data Scientist positions. The data is aggregated by the number of positions available in each state. The plot shows that California, Texas, New York, and Florida are the top states for both positions, with California having the highest number of positions available. This is expected as these states have high concentrations of technology companies and startups, which are the primary employers of data professionals. To add a layer of granularity, we can see that very few positions focus on education levels for both positions. However, Data scientist positions generally demand for a Masters or PhD degree alongwith a strong experience in analytics and expertise in ML models. Surprisingly, Massachusetts does not fall in the top 10 states which is our preferred state but with current labor market these initial signs suggest that relocation should be considered to keep enough options open.\n\n\n\nAnalysis - We first identified our preferred industry and those were Marketing (Unclassified industry), Healthcare and Finance. By plotting the job postings for both BA/DA and Data Scientist positions, we looked at which states have high postings for these industries. The above plot is specifically for BA/DA jobs, we can see that along the east cost these industries are more prominent, specially in NYC, Boston, Philadelphia and Washington. When we move to the west, the tight cluster as expected is around LA and San Jose in California. Finance industry is more prominent on the east likely because of the presence of Wall street in NYC.\n\n\n\nAnalysis- This plot focuses on the Data Science positions and it is evident that the number of jobs are considerably higher for this position regardless of the industry. The trend is similar to BA/DA positions in terms of clustering around east cost states and on the west coast in Sacramento, CA and San Jose. However, surprisingly for us Seattle has dense cluster for Healtcare and North Carolina and Chicago seem to have a big cluster for Marketing (Unclassified industry)\n\n\n5 Salary Comparison & Trends across both positions\n\n\n\nSalary distribution analysis: We have now moved to the monetary value offered by both positions and we already know that data science being the senior position commands higher salary but the purpose of this plot is to identify what is the sweet spot of the salary range where both positions lie in 2024. The peak for BA/DA positoions is between $80K-$100K. We can also see from the overlay plot that the violin plot starts to shrink immediately after $100K and the right tail is light compared to Data science positions. For Data Scientist the median salary is $120K and the upper fence is almost $240K with much heavier right tails which is likely influenced by the information sector where salaries for this position can be as good as senior software developer position.\n\n\n\nSalary distribution by Industry - In the previous plot, we compared salaries at the highest level, in this case we are being more specific to industries we are interested in (Unclassified for Marketing, Finance and Health care). For BA/DA positions we can see that Finance sector appears to be more lucrative compared to unclassified and Healthcare. Median salary for full time BA/DA role is $112K whereas for Marketing and Healthcare it is close to $95K which seems to be okay for full time positions but the range does fall as low as $40K which could be for junior or entry level positions which is worrisome specially for us as international students as there is benchmark for H1b approval in terms of salaries. In terms of Data Science, all the 3 industries are very lucrative as the average salary is well above $120K and can go as high as $220K. Finance and Insurance in this case display more rapid growth.\n\n\n6 Skills Trends Analysis across Business Analyst/Data Analyst and Data Scientist positions\n\n\n\n\n\n\nAnalysis Top 10 skills - The above plot highlights top 10 skills from each skill type (Common, Specialized and Software skills), this will give a full overview of what is required to be successful in the role and match the demands of the current labor market in these domains. In terms of common skills, we can see that common skills or so to say soft skills like communication, Management and Problem solving are in both roles but the presence is considerably higher in Data scientist. Communication as expected is at the highest because both these roles require high collaboration. Strangely for data scientist, the postings that require Python is less but that could also be because some postings have the tendency to include Python libraries instead of using the tool name because they are looking for specific candidates who should know these libraries. Computer Science seems to be one of the highest requirement for data science which can be influenced by the Information and Tech sector. On BA/DA roles, Dashboarding and Business Intelligence tools are on higher scale because that is what the role entails, there is consistent use of SQL and BI tools alongwith some use of Python.\n\n\n\n\n\n\nAverage Experience by Industry Analysis - When it comes to skills analysis, it is not just if a candidate knows the skill but how much experience is required also is critical. As per (Pushpa Singh & Garg, 2024), he and his co-authors had explained that the industry at this point in time is valuing experience of using the skills on real-world data than just backing of academic projects. Hence, as we step into the job market in search of an ideal job it is critical to know what are the demands of the companies in our preferred industries (Healthcare, Marketing and Finance) in terms of the number of years of experience. Although the average minimum years experience for all these 3 industry groups is above 3, we can speculate this is likely caused because of some of the executive positions failling under these industries. However, it is important to note that even after removing those outliers we should be speculating something aroun 0-2 years range and that highlights the importance of collaborating on real-world projects, internships and putting in the work beyond the academics.\n\n\n7 Machine Learning: Random Forest for predicting Salary\n\n\n8 Cleaning the target variable and features in the dataset: Feature Engineering\nFeature Selection - For continuous variables I have used minimum experience required for a job posting because that will be an indicator for junior and more senior level roles as we have some executive roles as well. For categorical variables, we have selected specialized skills because those skills ideally set the salary, for eg if we know SQL plus AWS services and how to work with RDS then we might command higher salary then those that know SQL and Excel but no cloud knowledge. Also we used Vectorizer instead of one Hot encoding just to limit the number of features and keep the computation stable.\n\n\n9 Splitting the prepared data into Training and Test set\n\n\n10 Visualizing Feature Importance\n\n\n\nTop 10 Rf imp\n\n\n\n\n11 Extracting evaluation metrics\n{include} ./data/rf_metrics_table.csv\nRF Evaluation & Analysis - From extracting the feature importances we know that minimum years experience plays a strong driver in predicting salary, however in terms of others like Enterprise Architecture, Data analysis and MapReduce are specialized skills and since we are using both Business Analyst and Data Scientist job postings to train this it is hard to evaluate if this would affect the salaries of both the positions in the same way. Mostly Mapreduce and cloud architecture are not the skills that are expected from a data analyst so this is likely attributed to Data Scientist. From the results it seems it would have been better to train the model and then make predictions using it separately for both positions, this would have limited the number of features and would have made the model more streamlined. If we look at the RMSE of the model it is deviating $29.6K from the actual salary values while making predictions which is acceptable considering the real-world factors where only skill sets and experience alone won’t determine the final value of the salary. However, these are strong drivers and from the R2 value the model is doing much better than capturing the mean value of the salary in the data range, however we would better look at RMSE values and features context than R2 for picking a model.\n\n\n12 Conclusion\nSummarizing the analysis from the various processes that we conducted above, we can briefly conclude that the market is extremely competitive at this stage, even though we did not look at specific AI trends from skills perspective we know that it has pushed the standards in the market up for data analysts as well by some margin. SQL is the core of data analysis be it data scientist or analyst, this tool becomes the first access point to data and is essential to condense the data into smaller subsets relatively to process it further of ML experimentation or insights reporting through dashboards. From an experience standpoint, simply completing Masters with generalized projects won’t make the cut, there has to be specific strategic learning process to get ahead of the clutter in the labor market. Lastly, in terms of further analysis we could further group the skills into subsets and use some NLP techniques to capture what specific skills in an industry can be mapped to either of these positions and what is common irrespective of the vertical. Although we are able to make some general statements about this but interesting patterns could be discovered from this analysis.\n\n\n\n\n\nReferences\n\nNobrega, S. (2024). The 5 data science skills you can’t ignore in 2024. https://towardsdatascience.com/the-5-data-science-skills-you-cant-ignore-in-2024-ceba3ea7726c\n\n\nPushpa Singh, A. R. M., & Garg, P. (2024). Data analytics and machine learning: Navigating the big data landscape (Vol. 145). Springer Nature. https://doi.org/10.1007/978-981-97-0448-4"
  },
  {
    "objectID": "job_trends_analysis_backup.html",
    "href": "job_trends_analysis_backup.html",
    "title": "Quantitative Analysis of Business Analytics, Data Science and Machine Learning",
    "section": "",
    "text": "1 Introduction to Quantitative Analysis\nNow that we had a deep dive in qualtitative analysis of Machine Learning, Data Analyst and Data Scientist positions, we want to leverage the Lightcast job postings data from 2024 to verify whether the findings from the research align with the current data from the market. One of the consistent themes from the research was an overlap between Machine Learning and Data Science positions because of skillsets required for these experienced roles. We will also explore if Business analyst/Data analyst positions have few most in-demand skillsets and what are they as these are foundational roles in data.\n\n\n2 Methodology\nThe first step would be to clean the dataset and identify the most relevant columns. Subset the data for Machine Learning, BA/DA and Data scientist positions data so these can be processed in silos Peform EDA for each role and highlight patterns or trends Perform Random Forest algorithms to predict salaries for these positions Summarise the findings\n\n\n3 Data Cleaning and Preprocessing\n\n\nCode\nimport pandas as pd\nimport numpy as np\nimport plotly.express as px\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport polars as pl\nfrom pyspark.sql import SparkSession\nimport plotly.io as pio\nnp.random.seed(42)\n\npio.renderers.default = \"notebook+notebook_connected+vscode\"\n# Start a Spark session\nspark = SparkSession.builder.appName(\"JobPostingsAnalysis\").getOrCreate()\n# Load the CSV file into a Spark DataFrame\ndf = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"multiLine\",\"true\").option(\"escape\", \"\\\"\").csv(\"./data/lightcast_job_postings.csv\")\n\n# Show schema\ndf.printSchema()\ndf.show(5, truncate = False)\n\n\n\n\nCode\n# Cleaning the dataset to remove redundant variables\ncols_to_drop = [\"ID\", \"LAST_UPDATED_DATE\", \"LAST_UPDATED_TIMESTAMP\", \"DUPLICATES\", \"SOURCE_TYPES\",\"SOURCES\", \"BODY\", \"COMPANY\", \"COMPANY_RAW\", \"TITLE_RAW\",\n                 \"URL\", \"ACTIVE_URLs\", \"POSTED\", \"EXPIRED\", \"DURATION\", \"ACTIVE_SOURCES_INFO\", \"MODELED_EXPIRED\", \"MODELED_DURATION\", \"EDUCATION_LEVELS\", \n                 \"MIN_EDULEVELS\", \"MIN_EDULEVELS_NAME\", \"MAX_EDULEVELS\", \"COMPANY_IS_STAFFING\", \"EMPLOYMENT_TYPE\", \"IS_INTERNSHIP\", \"ORIGINAL_PAY_PERIOD\", \"REMOTE_TYPE\", \"CITY\", \"COUNTY\", \"STATE\", \"COUNTY_OUTGOING\",\n                   \"COUNTY_NAME_OUTGOING\", \"COUNTY_INCOMING\", \"COUNTY_NAME_INCOMING\", \"MSA_OUTGOING\", \"MSA_NAME_OUTGOING\", \"MSA_INCOMING\", \"MSA_NAME_INCOMING\", \"NAICS2\",\n                     \"NAICS2_NAME\", \"NAICS3\", \"NAICS3_NAME\", \"NAICS4\", \"NAICS4_NAME\", \"NAICS5\", \"NAICS5_NAME\", \"NAICS6\", \"NAICS6_NAME\", \"TITLE\", \"TITLE_NAME\", \"SKILLS\",\n                       \"SPECIALIZED_SKILLS\", \"CERTIFICATIONS\", \"CERTIFICATIONS_NAME\", \"COMMON_SKILLS\", \"SOFTWARE_SKILLS\", \"ONET\", \"ONET_2019\", \"ONET_2019_NAME\", \"CIP6\", \"CIP6_NAME\", \"CIP4\",\n                         \"CIP4_NAME\", \"CIP2\", \"CIP2_NAME\", \"SOC_2021_2\", \"SOC_2021_3\", \"SOC_2021_4\", \"SOC_2021_5\", \"LOT_CAREER_AREA\", \"LOT_OCCUPATION\", \"LOT_SPECIALIZED_OCCUPATION\", \"LOT_OCCUPATION_GROUP\", \n                         \"LOT_OCCUPATION_GROUP_NAME\", \"LOT_V6_SPECIALIZED_OCCUPATION\", \"LOT_V6_OCCUPATION\", \"LOT_V6_OCCUPATION_GROUP\", \"LOT_V6_OCCUPATION_GROUP_NAME\", \"LOT_V6_CAREER_AREA\", \"LOT_V6_CAREER_AREA_NAME\", \"SOC_2\",\n                           \"SOC_2_NAME\", \"SOC_3\", \"SOC_3_NAME\", \"SOC_4\", \"SOC_4_NAME\", \"SOC_5\", \"SOC_5_NAME\", \"LIGHTCAST_SECTORS\", \"LIGHTCAST_SECTORS_NAME\", \"NAICS_2022_2\", \"NAICS_2022_3\", \"NAICS_2022_4\", \"NAICS_2022_5\", \"NAICS_2022_6\",\n                           \"MSA\", \"MSA_NAME\"]\ndf_cleaned = df.drop(*cols_to_drop)\ndf_cleaned.show(5, truncate = False)\n\n\n\n\nCode\n# Listing data types of the cleaned DataFrame\ndf_cleaned.dtypes\n\n\n\n\nCode\n# Converting spark dataframe to SQL table to have subsets for Machine Learning positions.\ndf_cleaned.createOrReplaceTempView(\"job_postings_data\")\n\nml_data_df = spark.sql(\"\"\"\n                            SELECT *\n                            FROM job_postings_data\n                            WHERE SALARY IS NOT NULL\n                            AND SALARY &gt; 0\n                            AND TITLE_CLEAN LIKE '%machine learning%';\n                            \"\"\")\nml_data_pd = ml_data_df.toPandas()\nml_data_pd.info()\n\n\n\n\nCode\nml_data_df.select(\"TITLE_CLEAN\").distinct().show(10, truncate=False)\n\n\nML specific positions are limited in title clean - Since we cannot seem to distinguish the data between Data Science and Machine Learning, from the dataset using job titles, we will focus on Data Scientist and Business Analyst positions. Qualitative data also suggested a strong overlap between Data Science and Machine Learning positions because the current job market expects candidates for Data scientist positions to have skills in not just ML models but production deployment and Artificial intelligence as well. (Nobrega, 2024)\n\n\nCode\n# Subsetting the main dataframe for Business Analyst, Data Analyst and Business Intelligence positions.\n\nba_da_data_df = spark.sql(\"\"\"\n                         SELECT *\n                         FROM job_postings_data\n                            WHERE SALARY IS NOT NULL\n                            AND SALARY &gt; 0\n                            AND LOT_SPECIALIZED_OCCUPATION_NAME IN ('Business Intelligence Analyst',\n                              'Business Analyst (General)', 'Data Analyst');\n\"\"\")\n\nba_da_data_pd = ba_da_data_df.toPandas()\n\n\n\n\nCode\n# Subsetting the main dataframe for Data Science positions.\nds_data_df = spark.sql(\"\"\"\n                      SELECT *\n                      FROM job_postings_data\n                        WHERE SALARY IS NOT NULL\n                        AND SALARY &gt; 0\n                        AND SOC_2021_5_NAME = 'Data Scientists';\n\"\"\")\nds_data_pd = ds_data_df.toPandas()\n\n\n\n\nCode\n# Condensing both dataframes to remove additional unncessary columns.\nba_da_cols_to_drop = ['ONET_NAME', 'SOC_2021_2_NAME', 'SOC_2021_3_NAME', 'SOC_2021_4_NAME',\n       'SOC_2021_5_NAME', 'LOT_CAREER_AREA_NAME', 'LOT_OCCUPATION_NAME','LOT_V6_SPECIALIZED_OCCUPATION_NAME',\n       'LOT_V6_OCCUPATION_NAME', 'NAICS_2022_4_NAME', 'NAICS_2022_3_NAME', 'NAICS_2022_5_NAME', 'NAICS_2022_6_NAME',  'MAX_YEARS_EXPERIENCE', 'MAX_EDULEVELS_NAME']\nba_da_data_pd = ba_da_data_pd.drop(columns=ba_da_cols_to_drop, axis=1) \nba_da_data_pd.info()\n\n\n\n\nCode\n# Removing job postings with no titles and min years of experience\nba_da_data_pd = ba_da_data_pd.dropna(subset = ['TITLE_CLEAN'])\nba_da_data_pd = ba_da_data_pd.dropna(subset = ['MIN_YEARS_EXPERIENCE'])\nba_da_data_pd.info()\n\n\n\n\nCode\nds_data_cols_to_drop = ['ONET_NAME', 'SOC_2021_2_NAME', 'SOC_2021_3_NAME', 'SOC_2021_4_NAME','LOT_CAREER_AREA_NAME', \n                        'LOT_OCCUPATION_NAME','LOT_SPECIALIZED_OCCUPATION_NAME', 'LOT_V6_SPECIALIZED_OCCUPATION_NAME',\n                        'LOT_V6_OCCUPATION_NAME', 'NAICS_2022_4_NAME', 'NAICS_2022_3_NAME','NAICS_2022_5_NAME', 'NAICS_2022_6_NAME',\n                        'MAX_YEARS_EXPERIENCE', 'MAX_EDULEVELS_NAME']\nds_data_pd = ds_data_pd.drop(columns=ds_data_cols_to_drop, axis=1) \nds_data_pd.info() \n\n\n\n\nCode\n# Removing job postings with no titles and min years of experience\nds_data_pd = ds_data_pd.dropna(subset = ['TITLE_CLEAN'])\nds_data_pd = ds_data_pd.dropna(subset = ['MIN_YEARS_EXPERIENCE'])\nds_data_pd.info()\n\n\n\n\nCode\n# Sorting categories under remote type name for both dataframes\nba_da_data_pd['REMOTE_TYPE_NAME'].unique()\nba_da_data_pd['REMOTE_TYPE'] = ba_da_data_pd['REMOTE_TYPE_NAME'].replace({\n    '[None]': 'Onsite',\n    'Not Remote': 'Onsite',\n    'Hybrid Remote': 'Hybrid',\n    'Remote': 'Remote'\n}).astype('category')\n\nds_data_pd['REMOTE_TYPE_NAME'] = ds_data_pd['REMOTE_TYPE_NAME'].replace({\n    '[None]': 'Onsite',\n    'Not Remote': 'Onsite',\n    'Hybrid Remote': 'Hybrid',\n    'Remote': 'Remote'\n}).astype('category')\n\n# Sorting categories under employment type name for both dataframes\nba_da_data_pd['EMPLOYMENT_TYPE_NAME'].astype('category')\nds_data_pd['EMPLOYMENT_TYPE_NAME'].astype('category')\n\n\n\n\nCode\nba_da_data_pd['EDUCATION_LEVELS_NAME'].unique()\n\n\n\n\nCode\n# Converting education levels into 2 categories Bachelor's or lower and Master's or PhD\nimport ast # Using ast.literal_eval to first convert stringified lists into python lists \nimport re # Need to remove those extra spaces in the Masters degree for proper classification\n\ndef clean_text(text):\n    text = text.replace(\"\\n\", \" \") \n    text = re.sub(r\"0\\s+\", \" \", text)  # Replacing those multiple spaces with single space for Masters degree\n    return text.strip()\n\n\ndef classify_education_level(edu_levels):\n    try:\n        levels = ast.literal_eval(edu_levels)\n\n        levels = [clean_text(level) for level in levels] \n\n        # defining categories now \n        Bachelors_or_lower = {\"Bachelor's degree\", \"Associate degree\", \"No Education Listed\", \"High school or GED\"}\n        Masters_or_PhD = {\"Master's degree\", \"Ph.D. or professional degree\"}\n\n        # Now applying IF logic\n        if any(level in Bachelors_or_lower for level in levels):\n            return \"Bachelors_or_lower\"\n        elif any(level in Masters_or_PhD for level in levels):\n            return \"Masters_or_PhD\"\n        else:\n            return \"Other\"\n    except:\n        return \"Unknown\"\n\n # Now we apply it to both dataframes \nba_da_data_pd['EDUCATION_LEVELS'] = ba_da_data_pd['EDUCATION_LEVELS_NAME'].apply(classify_education_level).astype('category')\nds_data_pd['EDUCATION_LEVELS'] = ds_data_pd['EDUCATION_LEVELS_NAME'].apply(classify_education_level).astype('category')\n\n\n\n\n\nCode\nba_da_data_pd['EDUCATION_LEVELS'].unique()\nds_data_pd['EDUCATION_LEVELS'].unique()\n\n\n\n\nCode\n# Separating Longitude and Latitude from the location column for maps visualization\ndef extract_lat_long(location):\n    try:\n        loc_dict = ast.literal_eval(location.replace(\"\\n\", \" \").strip())\n        return pd.Series([loc_dict.get(\"lat\"), loc_dict.get(\"lon\")])\n    except:\n        return pd.Series([None, None])\n    \nba_da_data_pd[['LATITUDE', 'LONGITUDE']] = ba_da_data_pd['LOCATION'].apply(extract_lat_long)\nds_data_pd[['LATITUDE', 'LONGITUDE']] = ds_data_pd['LOCATION'].apply(extract_lat_long)\n\n\n\n\nCode\nba_da_data_pd[[\"LONGITUDE\", \"LATITUDE\"]].head(5)\n\n\n\n\nCode\nba_da_data_pd.drop(columns=['REMOTE_TYPE_NAME', 'EDUCATION_LEVELS_NAME', \n                            'LOCATION'], axis = 1, inplace = True)\nds_data_pd.drop(columns=['REMOTE_TYPE_NAME', 'EDUCATION_LEVELS_NAME',\n                        'LOCATION'], axis = 1, inplace = True)\n\n\nSummarizing the cleaning of data for both positions: The most important data cleaning steps performed here were slicing the data for each position to process them individually. Location column was separated into Latitude and Logitude to enable geographic analysis of job postings. Remote type, education levels and employment type columns were converted into categories to visualized summarized data. Skillsets columns will be cleaned at a later stage when we analyze top skills for each position and then progress into Machine Learning.\n\n\n4 Geographical analysis of Business Analytics, Data Science and Machine Learning\n\n\nCode\n# Since the data is ready we can now create comparison bar plots \n# Top 10 states with highest number of job postings for Business Analyst, Data Analyst and Data Scientist positions\nimport hvplot.pandas\n\nba_da_state_counts = (ba_da_data_pd.groupby(['STATE_NAME', 'EDUCATION_LEVELS']).size().reset_index(name='COUNT'))\nds_state_counts = (ds_data_pd.groupby(['STATE_NAME', 'EDUCATION_LEVELS']).size().reset_index(name='COUNT'))\n\ntop_states_da = (ba_da_state_counts.groupby('STATE_NAME')['COUNT'].sum().nlargest(10).index)\nba_da_top10 = (ba_da_state_counts[ba_da_state_counts['STATE_NAME'].isin(top_states_da)]).sort_values(by='COUNT', ascending=False)  \n\ntop_states_ds = (ds_state_counts.groupby('STATE_NAME')['COUNT'].sum().nlargest(10).index)\nds_top10 = (ds_state_counts[ds_state_counts['STATE_NAME'].isin(top_states_ds)]).sort_values(by='COUNT', ascending=False)\n\n# Plotting stacked bar plots \nba_da_plot = ba_da_top10.hvplot.bar(x='STATE_NAME', y='COUNT', by='EDUCATION_LEVELS', stacked=True, \n                        title='Top 10 States for BA and DA Positions',rot = 45,\n                        xlabel='States', ylabel='Number of Job Postings', width=500, height=400)    \nds_plot = ds_top10.hvplot.bar(x='STATE_NAME', y='COUNT', by='EDUCATION_LEVELS', stacked=True,\n                    title='Top 10 States for Data Scientist Positions',rot = 45,\n                    xlabel='States', ylabel='Number of Job Postings', width=500, height=400)\ncombined_plot = (ba_da_plot + ds_plot).opts(shared_axes=False)\ncombined_plot\n\n# Saving the plot for HTML rendering\nfrom holoviews import save\nhvplot.save(combined_plot, './visualizations/top_states_job_postings.html', fmt ='html')\n\n\n\n\nCode\ncombined_plot\n\n\nAnalysis - Our first step in laying our career path is to narrow down the geographical locations where the positions are frequently available, so we have better chance of landing a job. Higher the number of positions available in a location, higher the chances of landing a job even though the competition is high, the odds of receiving an offer remain optimistic. The above plot is an hvplot providing a side by side comparison of top 10 states in the US for Business Analyst/Data Analyst and Data Scientist positions. The data is aggregated by the number of positions available in each state. The plot shows that California, Texas, New York, and Florida are the top states for both positions, with California having the highest number of positions available. This is expected as these states have high concentrations of technology companies and startups, which are the primary employers of data professionals. To add a layer of granularity, we can see that very few positions focus on education levels for both positions. However, Data scientist positions generally demand for a Masters or PhD degree alongwith a strong experience in analytics and expertise in ML models. Surprisingly, Massachusetts does not fall in the top 10 states which is our preferred state but with current labor market these initial signs suggest that relocation should be considered to keep enough options open.\n\n\nCode\n# Geospatial analysis of top 10 industries that have BA/DA positions\nba_da_ind_counts = (ba_da_data_pd.groupby(\"NAICS_2022_2_NAME\").size().reset_index(name = \"COUNT\").sort_values(by = \"COUNT\", \n                                                                                                              ascending = False).head(10))\n\nba_da_filtered = ba_da_data_pd[ba_da_data_pd[\"NAICS_2022_2_NAME\"].isin(ba_da_ind_counts[\"NAICS_2022_2_NAME\"])]\nba_da_filtered = ba_da_filtered[(ba_da_filtered[\"LATITUDE\"] != 0) & (ba_da_filtered[\"LONGITUDE\"] != 0)]\n\n\nba_da_map = ba_da_filtered.hvplot.points(\"LONGITUDE\", y = \"LATITUDE\", geo = True, \n                                         tiles = True, c = \"NAICS_2022_2_NAME\", colorbar = False,\n                                         hover_cols = [\"NAICS_2022_2_NAME\", \"CITY_NAME\", \"STATE_NAME\", \"SALARY\"],\n                                         title = 'Top 10 Industries hiring for BA/DA positions',\n                                         width = 800, height = 500, xlim = (-130, -65), ylim = (24,50)).opts(\n                                             legend_position = \"bottom_left\", legend_opts = {'label_text_font_size': '5pt',\n                                                                                           'title_text_font_size': '4pt'})\nhvplot.save(ba_da_map, \"./visualizations/ba_da_indgeomap.html\")                                         \nba_da_map\n\n\nAnalysis - We first identified our preferred industry and those were Marketing (Unclassified industry), Healthcare and Finance. By plotting the job postings for both BA/DA and Data Scientist positions, we looked at which states have high postings for these industries. The above plot is specifically for BA/DA jobs, we can see that along the east cost these industries are more prominent, specially in NYC, Boston, Philadelphia and Washington. When we move to the west, the tight cluster as expected is around LA and San Jose in California. Finance industry is more prominent on the east likely because of the presence of Wall street in NYC.\n\n\nCode\n# Geospatial analysis of top 10 industries that have Data scientist positions\nds_ind_counts = (ds_data_pd.groupby(\"NAICS_2022_2_NAME\").size().reset_index(name = \"COUNT\").sort_values(by = \"COUNT\", \n                                                                                                              ascending = False).head(10))\n\nds_filtered = ds_data_pd[ds_data_pd[\"NAICS_2022_2_NAME\"].isin(ds_ind_counts[\"NAICS_2022_2_NAME\"])]\nds_filtered = ds_filtered[(ds_filtered[\"LATITUDE\"] != 0) & (ds_filtered[\"LONGITUDE\"] != 0)]\n\n\nds_map = ds_filtered.hvplot.points(\"LONGITUDE\", y = \"LATITUDE\", geo = True, \n                                         tiles = True, c = \"NAICS_2022_2_NAME\", colorbar = False,\n                                         hover_cols = [\"NAICS_2022_2_NAME\", \"CITY_NAME\", \"STATE_NAME\", \"SALARY\"],\n                                         title = 'Top 10 Industries hiring for BA/DA positions',\n                                         width = 800, height = 500, xlim = (-130, -65), ylim = (24,50)).opts(\n                                             legend_position = \"bottom_left\", legend_opts = {'label_text_font_size': '5pt',\n                                                                                           'title_text_font_size': '4pt'})\nhvplot.save(ds_map, \"./visualizations/ds_indgeomap.html\")                                         \nds_map\n\n\nAnalysis- This plot focuses on the Data Science positions and it is evident that the number of jobs are considerably higher for this position regardless of the industry. The trend is similar to BA/DA positions in terms of clustering around east cost states and on the west coast in Sacramento, CA and San Jose. However, surprisingly for us Seattle has dense cluster for Healtcare and North Carolina and Chicago seem to have a big cluster for Marketing (Unclassified industry)\n\n\n5 Salary Comparison & Trends across both positions\n\n\nCode\n# Combining both dataframes to create overlayed histograms \nba_da_data_pd[\"ROLE\"] = \"BA/DA\"\nds_data_pd[\"ROLE\"] = \"Data Scientist\"\ncombined_df = pd.concat([ba_da_data_pd, ds_data_pd])\n\ncombined_hist = px.histogram(combined_df, x = \"SALARY\", color = \"ROLE\", \n                             nbins = 50, barmode = \"overlay\", histnorm = \"probability density\",\n                             title = \"Salary distributions for BA/DA and Data Scientists\",\n                             marginal = \"violin\")\ncombined_hist.update_traces(opacity = 0.75)\n\nimport kaleido\ncombined_hist.write_html(\"./visualizations/salary_distribution.html\")\ncombined_hist.write_image(\"./visualizations/salary_distribution.png\")\n\ncombined_hist.show()\n\n\nSalary distribution analysis: We have now moved to the monetary value offered by both positions and we already know that data science being the senior position commands higher salary but the purpose of this plot is to identify what is the sweet spot of the salary range where both positions lie in 2024. The peak for BA/DA positoions is between $80K-$100K. We can also see from the overlay plot that the violin plot starts to shrink immediately after $100K and the right tail is light compared to Data science positions. For Data Scientist the median salary is $120K and the upper fence is almost $240K with much heavier right tails which is likely influenced by the information sector where salaries for this position can be as good as senior software developer position.\n\n\nCode\n# Salary distribution and employment type (Faceted)\ntop10_ba_da_inds = ba_da_data_pd['NAICS_2022_2_NAME'].value_counts().nlargest(10).index\ntop10_ds_inds = ds_data_pd['NAICS_2022_2_NAME'].value_counts().nlargest(10).index\n\n# Filtering datasets to include only top 10 industries to keep it consistent with other plots\nba_da_filt1 = ba_da_data_pd[ba_da_data_pd['NAICS_2022_2_NAME'].isin(top10_ba_da_inds)]\nds_filt1 = ds_data_pd[ds_data_pd['NAICS_2022_2_NAME'].isin(top10_ds_inds)]\n\nimport plotly.graph_objects as go\n\n# Create BA/DA box plot with industry in legend and employment type as facets\nba_da_emp_ind = px.box(\n    ba_da_filt1, \n    y='SALARY',  \n    x='EMPLOYMENT_TYPE_NAME',             \n    color='NAICS_2022_2_NAME', \n    height=700,\n    width=1000)\n\n# Data Scientist plot\nds_emp_ind = px.box(\n    ds_filt1, \n    y='SALARY',\n    x='EMPLOYMENT_TYPE_NAME',\n    color='NAICS_2022_2_NAME',\n    height=700,\n    width=1000)\nimport plotly.graph_objects as go\ndist_fig = go.Figure()\n\nfor trace in ba_da_emp_ind.data:\n    trace.visible = True\n    dist_fig.add_trace(trace)\nfor trace in ds_emp_ind.data:\n    trace.visible = False  \n    dist_fig.add_trace(trace)\n\nn_ba_da = len(ba_da_emp_ind.data)\nn_ds = len(ds_emp_ind.data)\n\ndropdown_buttons = [\n    dict(label=\"BA/DA\",\n         method=\"update\",\n         args=[{\"visible\": [i &lt; n_ba_da for i in range(n_ba_da + n_ds)]},\n               {\"title\": \"BA/DA Salary Distribution by Employment Type and Industry (Top 10)\"}]),\n\n    dict(label=\"Data Scientist\",\n         method=\"update\",\n         args=[{\"visible\": [i &gt;= n_ba_da for i in range(n_ba_da + n_ds)]},\n               {\"title\": \"Data Scientist Salary Distribution by Employment Type and Industry (Top 10)\"}])\n]\n\n# Update layout with dropdown\ndist_fig.update_layout(\n    updatemenus=[dict(\n        buttons=dropdown_buttons,\n        direction=\"down\",\n        showactive=True,\n        x=0.5,\n        xanchor=\"center\",\n        y=1.15,\n        yanchor=\"top\"\n    )],\n    xaxis_title=\"Employment Type\",\n    yaxis_title=\"Salary\",\n    legend_title=\"Industry\",\n    height=700,\n    width=1000,\n    boxmode=\"group\"\n)\ndist_fig.write_html(\"./visualizations/salary_dist_emp_ind.html\")\ndist_fig.write_image(\"./visualizations/salary_dist_emp_ind.png\")\ndist_fig.show()\n\n\nSalary distribution by Industry - In the previous plot, we compared salaries at the highest level, in this case we are being more specific to industries we are interested in (Unclassified for Marketing, Finance and Health care). For BA/DA positions we can see that Finance sector appears to be more lucrative compared to unclassified and Healthcare. Median salary for full time BA/DA role is $112K whereas for Marketing and Healthcare it is close to $95K which seems to be okay for full time positions but the range does fall as low as $40K which could be for junior or entry level positions which is worrisome specially for us as international students as there is benchmark for H1b approval in terms of salaries. In terms of Data Science, all the 3 industries are very lucrative as the average salary is well above $120K and can go as high as $220K. Finance and Insurance in this case display more rapid growth.\n\n\n6 Skills Trends Analysis across Business Analyst/Data Analyst and Data Scientist positions\n\n\nCode\n# Cleaning skills column to get them as list for each row and continue with analysis \ndef clean_skills_column(df, col):\n    df[col] = df[col].apply(lambda x: ast.literal_eval(x) if pd.notnull(x) else [])\n    df[col] = df[col].apply(lambda lst: [i.strip().replace(\"\\n\", \"\") for i in lst])\n    return df\n\nskill_cols = ['COMMON_SKILLS_NAME', 'SOFTWARE_SKILLS_NAME', 'SPECIALIZED_SKILLS_NAME']\n\nfor col in skill_cols:\n    ba_da_data_pd = clean_skills_column(ba_da_data_pd, col)\n    ds_data_pd = clean_skills_column(ds_data_pd, col)\n\n\n\n\nCode\n# Our thought process is to visualize first the top 10 skills for each role and based on how many times they appear \n# Respective job postings and then get granular\ndef process_skills(df, role, skill_col):\n    temp = df[['NAICS_2022_2_NAME', 'SALARY', skill_col]].copy()\n    temp['ROLE'] = role\n    temp = temp.rename(columns={skill_col: 'SKILLS', 'NAICS_2022_2_NAME': 'INDUSTRY'})\n    temp = temp.explode('SKILLS')\n    temp = temp.dropna(subset=['SKILLS'])\n    temp['SKILL_TYPE'] = skill_col.replace('_NAME', '').title().replace('_', ' ')\n    return temp.rename(columns={'SKILLS': 'SKILL'})\n\nskill_data = []\nfor col in skill_cols:\n    skill_data.append(process_skills(ba_da_data_pd, 'BA/DA', col))\n    skill_data.append(process_skills(ds_data_pd, 'Data Scientist', col))\n\nall_skills = pd.concat(skill_data, ignore_index=True)\n\n\n\n\nCode\nba_da_top_skills = {}\nds_top_skills = {}\n\nroles_data = {\n    'BA/DA': all_skills[all_skills['ROLE'] == 'BA/DA'],\n    'Data Scientist': all_skills[all_skills['ROLE'] == 'Data Scientist']\n}\n\nfor role, role_df in roles_data.items():\n    skill_type_dict = {}\n    for skill_type in role_df['SKILL_TYPE'].unique():\n        temp_df = role_df[role_df['SKILL_TYPE'] == skill_type]\n        top_10_series= (\n            temp_df['SKILL']\n            .value_counts()\n            .nlargest(10)\n        )\n        top_10_df = top_10_series.reset_index()\n        top_10_df.columns = ['SKILL', 'COUNT']\n        skill_type_dict[skill_type] = top_10_df\n    \n    if role == 'BA/DA':\n        ba_da_top_skills = skill_type_dict\n    else:\n        ds_top_skills = skill_type_dict\n\n\n\n\n\nCode\nimport plotly.graph_objects as go\n\ndef create_bubble_chart(role_name, role_data):\n    skill_bubble = go.Figure()\n    buttons = []\n    trace_count = 0\n    \n    for i, (skill_type, df) in enumerate(role_data.items()):\n        visible = [False] * len(role_data)\n        visible[i] = True  # show only the selected skill type initially\n        \n        skill_bubble.add_trace(go.Scatter(\n            x=df['SKILL'],\n            y=df['COUNT'],\n            mode='markers+text',\n            text=df['SKILL'],\n            textposition='top center',\n            textfont= dict(size = 7),\n            marker=dict(\n                size=df['COUNT'],\n                sizemode='area',\n                sizeref=2. * df['COUNT'].max() / (40. ** 2),\n                sizemin=10\n            ),\n            name=skill_type,\n            visible=True if i == 0 else False\n        ))\n\n        buttons.append(dict(\n            label=skill_type,\n            method='update',\n            args=[\n                {'visible': [j == i for j in range(len(role_data))]},\n                {'title': f\"{role_name} - {skill_type}\"}\n            ]\n        ))\n\n    skill_bubble.update_layout(\n        title=f\"{role_name} - {list(role_data.keys())[0]}\",\n        updatemenus=[dict(\n            buttons=buttons,\n            direction=\"down\",\n            showactive=True,\n            x=0.1,\n            y=1.15\n        )],\n        xaxis_title=\"Skill\",\n        yaxis_title=\"Count\",\n        height=600\n    )\n\n    return skill_bubble\n\n# Create and display\nskill_bubble_ba_da = create_bubble_chart(\"BA/DA\", ba_da_top_skills)\nskill_bubble_ds = create_bubble_chart(\"Data Scientist\", ds_top_skills)\n\nskill_bubble_ba_da.write_html(\"./visualizations/skill_bubble_ba.html\")\nskill_bubble_ba_da.write_image(\"./visualizations/skill_bubble_ba.png\")\nskill_bubble_ds.write_html(\"./visualizations/skill_bubble_ds.html\")\nskill_bubble_ds.write_image(\"./visualizations/skill_bubble_ds.png\")\n\nskill_bubble_ba_da.show()\nskill_bubble_ds.show()\n\n\nAnalysis Top 10 skills - The above plot highlights top 10 skills from each skill type (Common, Specialized and Software skills), this will give a full overview of what is required to be successful in the role and match the demands of the current labor market in these domains. In terms of common skills, we can see that common skills or so to say soft skills like communication, Management and Problem solving are in both roles but the presence is considerably higher in Data scientist. Communication as expected is at the highest because both these roles require high collaboration. Strangely for data scientist, the postings that require Python is less but that could also be because some postings have the tendency to include Python libraries instead of using the tool name because they are looking for specific candidates who should know these libraries. Computer Science seems to be one of the highest requirement for data science which can be influenced by the Information and Tech sector. On BA/DA roles, Dashboarding and Business Intelligence tools are on higher scale because that is what the role entails, there is consistent use of SQL and BI tools alongwith some use of Python.\n\n\nCode\n# Average Min years of experience required across Industries for BA/DA and Data Science positions\n\n# Calculating average experience (minimum) per industry for each role\navg_exp_by_industry_role = (\n    combined_df.groupby(['ROLE', 'NAICS_2022_2_NAME'])\n    .agg(AVG_MIN_EXPERIENCE=('MIN_YEARS_EXPERIENCE', 'mean'))\n    .reset_index()\n    .rename(columns={'NAICS_2022_2_NAME': 'INDUSTRY'})\n)\n\nba_df = avg_exp_by_industry_role[avg_exp_by_industry_role['ROLE'] == 'BA/DA'].sort_values(by='AVG_MIN_EXPERIENCE', ascending=False)\nds_df = avg_exp_by_industry_role[avg_exp_by_industry_role['ROLE'] == 'Data Scientist'].sort_values(by='AVG_MIN_EXPERIENCE', ascending=False)\n\nhbar_ba = px.bar(\n    ba_df,\n    x='AVG_MIN_EXPERIENCE',\n    y='INDUSTRY',\n    orientation='h',\n    title='Avg Min Years of Experience by Industry – BA/DA',\n    labels={'AVG_MIN_EXPERIENCE': 'Avg Min Experience', 'INDUSTRY': 'Industry'},\n    height=800\n)\nhbar_ba.update_layout(yaxis=dict(tickfont=dict(size=10)))\n\nhbar_ds = px.bar(\n    ds_df,\n    x='AVG_MIN_EXPERIENCE',\n    y='INDUSTRY',\n    orientation='h',\n    title='Avg Min Years of Experience by Industry – Data Scientist',\n    labels={'AVG_MIN_EXPERIENCE': 'Avg Min Experience', 'INDUSTRY': 'Industry'},\n    height=800\n)\n\nhbar_ds.update_layout(yaxis=dict(tickfont=dict(size=10)))\nhbar_ba.write_html(\"./visualizations/avg_exp_indba.html\")\nhbar_ba.write_image(\"./visualizations/avg_exp_indba.png\", width=1000, height=800, scale=2)\nhbar_ds.write_html(\"./visualizations/avg_exp_indds.html\")\nhbar_ds.write_image(\"./visualizations/avg_exp_indds.png\", width=1000, height=800, scale=2)\n\nhbar_ba.show()\nhbar_ds.show()\n\n\nAverage Experience by Industry Analysis - When it comes to skills analysis, it is not just if a candidate knows the skill but how much experience is required also is critical. As per (Pushpa Singh & Garg, 2024), he and his co-authors had explained that the industry at this point in time is valuing experience of using the skills on real-world data than just backing of academic projects. Hence, as we step into the job market in search of an ideal job it is critical to know what are the demands of the companies in our preferred industries (Healthcare, Marketing and Finance) in terms of the number of years of experience. Although the average minimum years experience for all these 3 industry groups is above 3, we can speculate this is likely caused because of some of the executive positions failling under these industries. However, it is important to note that even after removing those outliers we should be speculating something aroun 0-2 years range and that highlights the importance of collaborating on real-world projects, internships and putting in the work beyond the academics.\n\n\n7 Machine Learning: Random Forest for predicting Salary\n\n\nCode\n# Converting pandas dataframes back into spark \nba_da_data_df = spark.createDataFrame(ba_da_data_pd)\nds_data_df = spark.createDataFrame(ds_data_pd)\n\n# Keeping only common columns in both dataframes\ncols_ba = set(ba_da_data_df.columns)\ncols_ds = set(ds_data_df.columns)\n\ncommon_cols = list(cols_ba.intersection(cols_ds))\n\nml_ba_da_df = ba_da_data_df.select(common_cols)\nml_ds_data_df = ds_data_df.select(common_cols)\n\n# Combining both dataframes for ML\nml_combined_df = ml_ba_da_df.unionByName(ml_ds_data_df)\n\n\n\n\n8 Cleaning the target variable and features in the dataset: Feature Engineering\n\n\nCode\nfrom pyspark.sql.functions import col, pow\nfrom pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, CountVectorizer\nfrom pyspark.ml import Pipeline\n\n# Dropping rows with NA values in the columns that will be used in the model \nml_df = ml_combined_df.dropna(subset=[\"SALARY\", \"MIN_YEARS_EXPERIENCE\", \"SPECIALIZED_SKILLS_NAME\",\n                     \"EDUCATION_LEVELS\"])\n\n# Using CountVectorizer instead of OneHotencoder to convert list of skills into a sparse vector\ncv = CountVectorizer(inputCol=\"SPECIALIZED_SKILLS_NAME\", outputCol=\"SKILLS_VEC\", vocabSize = 1000, binary =True )\n\n# Encoding these categorical variables \nindexers = StringIndexer(inputCol =  \"EDUCATION_LEVELS\", outputCol = \"EDU_IDX\", handleInvalid = \"skip\")\n\n# Using vector assembler to assemble features (for GLR and Random forest)\nassembler = VectorAssembler(inputCols = [\"MIN_YEARS_EXPERIENCE\"] + [\"EDU_IDX\"] + [\"SKILLS_VEC\"],\n                                         outputCol = \"features\")\n# Building the pipeline of target and features \ncv_model = cv.fit(ml_df)\nml_df = cv_model.transform(ml_df)\n\nindexers_model = indexers.fit(ml_df)\nml_df = indexers_model.transform(ml_df)\n\ndata = assembler.transform(ml_df)\n\n# Displaying the final structure\ndata.select(\"SALARY\", \"features\").show(5, truncate = True)\n\n\nFeature Selection - For continuous variables I have used minimum experience required for a job posting because that will be an indicator for junior and more senior level roles as we have some executive roles as well. For categorical variables, we have selected specialized skills because those skills ideally set the salary, for eg if we know SQL plus AWS services and how to work with RDS then we might command higher salary then those that know SQL and Excel but no cloud knowledge. Also we used Vectorizer instead of one Hot encoding just to limit the number of features and keep the computation stable.\n\n\n9 Splitting the prepared data into Training and Test set\n\n\nCode\ntrain_data, test_data = data.randomSplit([0.8, 0.2], seed = 317)\nprint((train_data.count()), len(train_data.columns))\nprint((test_data.count()), len(test_data.columns))\n\n\n\n\nCode\n# Excecuting Random Forest Model\n\n\n\n\nCode\nfrom pyspark.ml.regression import RandomForestRegressor\n\n# Initiating the model\nrf = RandomForestRegressor(featuresCol = \"features\", labelCol = \"SALARY\", numTrees = 150, maxDepth = 6, seed = 317)\n\n# Training the Random Forest model\nrf_model = rf.fit(train_data.select(\"SALARY\", \"features\"))\n\n# Generating predictions\nrf_preds = rf_model.transform(train_data.select(\"SALARY\", \"features\"))\n\n\n\n\nCode\nskill_features = cv_model.vocabulary  # List of strings\nall_feature_names = [\"MIN_YEARS_EXPERIENCE\", \"EDU_IDX\"] + skill_features\n\nimportances = rf_model.featureImportances.toArray()\nfeature_df = pd.DataFrame({\n    \"Feature\": all_feature_names,\n    \"Importance\": importances\n}).sort_values(by=\"Importance\", ascending=False)\n\n\n\n\n10 Visualizing Feature Importance\n\n\nCode\ntop_n = 10\ntop_features = feature_df.head(top_n)\n\nplt.figure(figsize=(10, 8))\nplt.barh(top_features['Feature'], top_features['Importance'], color='skyblue')\nplt.xlabel(\"Feature Importance\")\nplt.title(f\"Top {top_n} Feature Importances from Random Forest\")\nplt.gca().invert_yaxis()\nplt.tight_layout()\nplt.savefig(\"./visualizations/rf_feature_importance.png\", dpi=300, bbox_inches='tight')\nplt.show()\n\n\n\n\n11 Extracting evaluation metrics\n\n\nCode\nfrom pyspark.ml.evaluation import RegressionEvaluator\nevaluator = RegressionEvaluator(labelCol=\"SALARY\", predictionCol=\"prediction\")\n\nrmse = evaluator.setMetricName(\"rmse\").evaluate(rf_preds)\nr2 = evaluator.setMetricName(\"r2\").evaluate(rf_preds)\n\nmetrics_df = pd.DataFrame({\n    'Metric': ['Root Mean Squared Error (RMSE)', 'R² (Coefficient of Determination)'],\n    'Value': [round(rmse, 2), round(r2, 4)]\n})\nmetrics_df.to_csv(\"./data/rf_metrics_table.csv\")\nprint(metrics_df.to_string(index=False))\n\n\n25/06/29 19:55:36 WARN TaskSetManager: Stage 225 contains a task of very large size (9148 KiB). The maximum recommended task size is 1000 KiB.\n25/06/29 19:55:41 WARN TaskSetManager: Stage 226 contains a task of very large size (9148 KiB). The maximum recommended task size is 1000 KiB.\n[Stage 226:============================&gt;                            (2 + 2) / 4]\n\n\n                           Metric      Value\n   Root Mean Squared Error (RMSE) 29641.8400\nR² (Coefficient of Determination)     0.5159\n\n\n                                                                                \n\n\nRF Evaluation & Analysis - From extracting the feature importances we know that minimum years experience plays a strong driver in predicting salary, however in terms of others like Enterprise Architecture, Data analysis and MapReduce are specialized skills and since we are using both Business Analyst and Data Scientist job postings to train this it is hard to evaluate if this would affect the salaries of both the positions in the same way. Mostly Mapreduce and cloud architecture are not the skills that are expected from a data analyst so this is likely attributed to Data Scientist. From the results it seems it would have been better to train the model and then make predictions using it separately for both positions, this would have limited the number of features and would have made the model more streamlined. If we look at the RMSE of the model it is deviating $29.6K from the actual salary values while making predictions which is acceptable considering the real-world factors where only skill sets and experience alone won’t determine the final value of the salary. However, these are strong drivers and from the R2 value the model is doing much better than capturing the mean value of the salary in the data range, however we would better look at RMSE values and features context than R2 for picking a model.\n\n\n12 Conclusion\nSummarizing the analysis from the various processes that we conducted above, we can briefly conclude that the market is extremely competitive at this stage, even though we did not look at specific AI trends from skills perspective we know that it has pushed the standards in the market up for data analysts as well by some margin. SQL is the core of data analysis be it data scientist or analyst, this tool becomes the first access point to data and is essential to condense the data into smaller subsets relatively to process it further of ML experimentation or insights reporting through dashboards. From an experience standpoint, simply completing Masters with generalized projects won’t make the cut, there has to be specific strategic learning process to get ahead of the clutter in the labor market. Lastly, in terms of further analysis we could further group the skills into subsets and use some NLP techniques to capture what specific skills in an industry can be mapped to either of these positions and what is common irrespective of the vertical. Although we are able to make some general statements about this but interesting patterns could be discovered from this analysis.\n\n\n\n\n\nReferences\n\nNobrega, S. (2024). The 5 data science skills you can’t ignore in 2024. https://towardsdatascience.com/the-5-data-science-skills-you-cant-ignore-in-2024-ceba3ea7726c\n\n\nPushpa Singh, A. R. M., & Garg, P. (2024). Data analytics and machine learning: Navigating the big data landscape (Vol. 145). Springer Nature. https://doi.org/10.1007/978-981-97-0448-4"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to our Job trends analysis in ML, Data Science and Business Analytics project",
    "section": "",
    "text": "Welcome everyone!\nThis is a structure analysis of how three of the most competitive and rapidly evolving fields in data and tech are demanding candidates to constantly reskill and upskill. The purpose of the analysis is to identify patterns and gaps in the labour market and provide a summarized recommendation for ourselves and anyone interested in these domains so that we can land our dream jobs either in the United states or one’s home country.\nPlease read through both the qualitative and quantitative analysis for detailed walkthrough of the approach and results.\nGood Luck\n\n\n\nWelcome Banner"
  },
  {
    "objectID": "final_report_group1.html",
    "href": "final_report_group1.html",
    "title": "Individual Career Strategy based on Research and Quantitative analysis",
    "section": "",
    "text": "1 Welcome everyone!\nThis is a structure analysis of how three of the most competitive and rapidly evolving fields in data and tech are demanding candidates to constantly reskill and upskill. The purpose of the analysis is to identify patterns and gaps in the labour market and provide a summarized recommendation for ourselves and anyone interested in these domains so that we can land our dream jobs either in the United states or one’s home country.\nPlease read through both the qualitative and quantitative analysis for detailed walkthrough of the approach and results.\nGood Luck\n\n\n\nWelcome Banner\n\n\n\ntitle: “Qualitative Research on Business Analytics, Data Science and Machine Learning Trends” format: html: csl: apa.csl bibliography: references.bib —\n\n\n2 Selection Rationale:\nWe are at the early stages of our careers in the data analytics field, and as we look to pursue opportunities in the current, rapidly evolving U.S. market—specifically for data or business analysts—our priority is to focus on the critical requirements of data roles that help us fill any existing gaps in our skill set. Hence, we will conduct a qualitative deep dive into trends and recent changes in the analytics, data science, and machine learning domain before proceeding to verify whether this qualitative analysis is supported by the quantitative assessment of the Lightcast job posting data we have at hand.\nAlso, it is important to note that most data analytics principles can be applied to business analytics, as the two roles have a high degree of overlap. The former involves cleaning and processing data, while the latter (business analytics) takes those insights further and translates them into business decisions or improvements in policies, processes, or operations. In essence, data analytics focuses on the “what” and “why” from data, while business analytics goes further into developing the “how” and “what next” by leveraging those insights. (Jin Liu & Lyu, 2024)\n\n\n3 Introduction:\nThis is a brief overview of how the convergence of Data analytics, Big Data and Machine Learning has become an influential force in every business that relies on data-driven decision-making. It also covers how Industry 4.0 is revolutionizing the manufacturing as well as service processes all over the world. In simple words, Industry 4.0 is an amalgamation of multiple disciplines like Internet of Things (IoT), Industrial Internet of Things (IIoT), artificial intelligence, machine learning, hyper convergent Infrastructure, deep learning and virtualization, all these create a strong and intelligent production system for businesses that enable them to carve insights from heaps of data that they are collecting but at the same time translate them into actionable items that are strongly backed. (Li, 2022). The review then shift focus on the importance of reskilling and/or upskilling is critical to be part of the talent that realizes Industry 4.0 to realize its full potential.\nThe World Economic Forum projected that half of all employees worldwide would need to reskilling by 2025 in its future jobs report 2020. (Forum, 2020). Life-long learning is not a choice but a norm in 2025 with the advent of AI, advanced applications of machine learning and increase uncertainty around ability of AI to replace candidates with jobs that have tasks that have potential to be automated.\nThe top 10 skills comparison from 2015, 2020 to 2025: \nIn context of Data science and machine learning, these are most sought soft skills in 2025, however industry reports reveal that there is shortage of big data client in the field and companies prefer candidates that possess one to three years of experience because they can quickly adapt to changing industry needs and help companies realize their full potential backed by big data processing and analysis. (Yugal, 2022) The literature review delves into details of each domain, explaining how they have evolved and what is required for success in this fast-evolving tech space.\n\n\n4 Machine Learning Trends:\nAs the digital era continues to push the envelope of transformation, the trifecta or the combination of Data Analytics, Big Data and Machine learning becomes a vital source for businesses to search practical insights and long-term advancement. This intersection has necessitated the need for new skill sets to effectively analyze and interpret complex, high-volume data. To understand the required skills in this domain, it is important to understand the full range of applications of ML. It ranges from decision-making processes, modeling layout form, identification of results from data analysis, and forecast for big data analytics-oriented programs.\nIn terms of industry specific applications, in life sciences ML is progressively used as a analytical and computational tool for study of vast unstructured data of genome libraries to set up automated workflows. Virtual assistants have been powered by ML-enabled speech recognition technology. In combination with ML, Deep learning has become a potent instrument in variety of sectors like audio and picture identification, natural language processing and even medicine (Bhattacherjee & Badhan, 2024). For these a sustainable talent training system is required, and it becomes the mission and responsibility of educational institutions as well as individual candidates to realize the full-scale potential of this domain. For instance, deep learning libraries like PyTorch, TensorFlow, Keras and MXNet have recently been developed and if these are introduced as conceptual content to students in advance, it will place a foundation of big data talents at the forefront and address the shortage of experienced and skilled talents that the business are looking for. (Han & Ren, 2024) A cluster analysis of Big Data expertise needs provided scores for various variables for each tool, algorithms and techniques. \n\n\n5 Business Analytics Trends:\nWith the advent of AI and digital governance evolving rapidly, the Business analytics field has expanded beyond just managerial outlook and expertise in the business process with some level of analysis. The emergence of Big Data has led to the involvement of Business analysts in statistical analysis as well as processing of vast amounts of data to generate insights. BA & intelligence teams can take those insights further to translate them into business process improvements, development of new practices by generating dashboards or written reports for stakeholders. (Yugal, 2022) \nBA & I involves a lot more techniques post 2023 that are implemented to structure a process of business decision-making. AI/ML integration, Cloud based analytics, and predictive analytics are at the forefront of this domain as volume of data is expanding rapidly and so as the cloud infrastructure adoption to execute analytics and forecast trends, customer behavior and understand market dynamics. (Business Management & Research, n.d.)\n\n\n\nBA techniques\n\n\n\n\n6 Data Science Trends\nTo establish an understanding of this domain in simpler terms, one can say it is a step or few advanced to data analytics. It has high overlap with ML engineers and MLOps engineers and that makes sense in the real world as more and more companies expect their employees to have an understanding of a bit of everything because of the need of strong collaboration between these teams for each project.\nAbout 20,800 openings for data scientists are projected each year since 2024, on average over the decade. The growth of this space is expected to be 36% from 2023 to 2033, which is much faster than average of all the other occupations. (Labor Statistics, 2024)\nData science is more of an umbrella term that has been derived from industrial demand. The T-shaped configuration of skills is generally used to analyze the breadth of knowledge and skills required for a domain and to identify a functional area that one would like to gain expertise within that domain. The T-shape or π-shaped diagram for analytics is shown below: (Shirani, 2016) \nExploring the skillsets that have been dominant in data science roles across the board in recent years are below: ##Deep Learning: It is at the forefront of many in-demand frameworks right now, such as generative adversarial networks (GANs) and reinforcement learning which dive into artificial intelligence but as described in this entire review, each of these fields touch AI discipline in some form with data science and ML being closest to it. Sophisticated models like image classification, NLPs and anomaly detection use deep learning techniques and candidates who are looking to enter this space must have strong foundation of mathematical concepts (linear algebra, calculus, probability and statistics) and then should have understanding of core principles of deep learning – neural networks and backpropagation. (Nobrega, 2024)\n##Machine Learning Deployment: It is understood that experimenting various ML models on the data to capture patterns is a pre-requisite now, deploying the validated models in a production environment is crucial to derive business value. For this, candidates are required to have a strong grasp of fundamentals of ML, they should be familiar with one of the cloud platforms and should have understanding of deployment tools like Docker or Kubernetes. In addition to this, understanding of MLOps best practices and lifecycle management of ML models is also expected. Hence, it is clear that the role involves lifelong learning and hands on practice on the tools and to have all basics covered so that foundation for creativity can be laid when it comes to execution. (Nobrega, 2024)\n\n\n7 Conclusion:\nIt is evident that in the past 2 years, each role deals with vast amount of data and hence understanding of cloud infrastructure and big data techniques is essential for success in these roles. Although, the expertise or level of skills in these disciplines may vary for each role but it is essential to have curiosity and willingness to upskill and reskill as per the evolving needs in the analytics domain and overall business requirements to stay relevant in the market.\n\n\n8 References\n\n\n9 Introduction to Quantitative Analysis\nNow that we had a deep dive in qualtitative analysis of Machine Learning, Data Analyst and Data Scientist positions, we want to leverage the Lightcast job postings data from 2024 to verify whether the findings from the research align with the current data from the market. One of the consistent themes from the research was an overlap between Machine Learning and Data Science positions because of skillsets required for these experienced roles. We will also explore if Business analyst/Data analyst positions have few most in-demand skillsets and what are they as these are foundational roles in data.\n\n\n10 Methodology\nThe first step would be to clean the dataset and identify the most relevant columns. Subset the data for Machine Learning, BA/DA and Data scientist positions data so these can be processed in silos Peform EDA for each role and highlight patterns or trends Perform Random Forest algorithms to predict salaries for these positions Summarise the findings\n\n\n11 Data Cleaning and Preprocessing\n\n\nCode\nimport pandas as pd\nimport numpy as np\nimport plotly.express as px\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport polars as pl\nfrom pyspark.sql import SparkSession\nimport plotly.io as pio\nnp.random.seed(42)\n\npio.renderers.default = \"notebook+notebook_connected+vscode\"\n# Start a Spark session\nspark = SparkSession.builder.appName(\"JobPostingsAnalysis\").getOrCreate()\n# Load the CSV file into a Spark DataFrame\ndf = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"multiLine\",\"true\").option(\"escape\", \"\\\"\").csv(\"./data/lightcast_job_postings.csv\")\n\n# Show schema\n#df.show(5, truncate = False)\n\n\nSetting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n25/06/30 00:23:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n[Stage 0:&gt;                                                          (0 + 1) / 1]                                                                                [Stage 1:&gt;                                                          (0 + 1) / 1]                                                                                \n\n\n\n\nCode\n# Cleaning the dataset to remove redundant variables\ncols_to_drop = [\"ID\", \"LAST_UPDATED_DATE\", \"LAST_UPDATED_TIMESTAMP\", \"DUPLICATES\", \"SOURCE_TYPES\",\"SOURCES\", \"BODY\", \"COMPANY\", \"COMPANY_RAW\", \"TITLE_RAW\",\n                 \"URL\", \"ACTIVE_URLs\", \"POSTED\", \"EXPIRED\", \"DURATION\", \"ACTIVE_SOURCES_INFO\", \"MODELED_EXPIRED\", \"MODELED_DURATION\", \"EDUCATION_LEVELS\", \n                 \"MIN_EDULEVELS\", \"MIN_EDULEVELS_NAME\", \"MAX_EDULEVELS\", \"COMPANY_IS_STAFFING\", \"EMPLOYMENT_TYPE\", \"IS_INTERNSHIP\", \"ORIGINAL_PAY_PERIOD\", \"REMOTE_TYPE\", \"CITY\", \"COUNTY\", \"STATE\", \"COUNTY_OUTGOING\",\n                   \"COUNTY_NAME_OUTGOING\", \"COUNTY_INCOMING\", \"COUNTY_NAME_INCOMING\", \"MSA_OUTGOING\", \"MSA_NAME_OUTGOING\", \"MSA_INCOMING\", \"MSA_NAME_INCOMING\", \"NAICS2\",\n                     \"NAICS2_NAME\", \"NAICS3\", \"NAICS3_NAME\", \"NAICS4\", \"NAICS4_NAME\", \"NAICS5\", \"NAICS5_NAME\", \"NAICS6\", \"NAICS6_NAME\", \"TITLE\", \"TITLE_NAME\", \"SKILLS\",\n                       \"SPECIALIZED_SKILLS\", \"CERTIFICATIONS\", \"CERTIFICATIONS_NAME\", \"COMMON_SKILLS\", \"SOFTWARE_SKILLS\", \"ONET\", \"ONET_2019\", \"ONET_2019_NAME\", \"CIP6\", \"CIP6_NAME\", \"CIP4\",\n                         \"CIP4_NAME\", \"CIP2\", \"CIP2_NAME\", \"SOC_2021_2\", \"SOC_2021_3\", \"SOC_2021_4\", \"SOC_2021_5\", \"LOT_CAREER_AREA\", \"LOT_OCCUPATION\", \"LOT_SPECIALIZED_OCCUPATION\", \"LOT_OCCUPATION_GROUP\", \n                         \"LOT_OCCUPATION_GROUP_NAME\", \"LOT_V6_SPECIALIZED_OCCUPATION\", \"LOT_V6_OCCUPATION\", \"LOT_V6_OCCUPATION_GROUP\", \"LOT_V6_OCCUPATION_GROUP_NAME\", \"LOT_V6_CAREER_AREA\", \"LOT_V6_CAREER_AREA_NAME\", \"SOC_2\",\n                           \"SOC_2_NAME\", \"SOC_3\", \"SOC_3_NAME\", \"SOC_4\", \"SOC_4_NAME\", \"SOC_5\", \"SOC_5_NAME\", \"LIGHTCAST_SECTORS\", \"LIGHTCAST_SECTORS_NAME\", \"NAICS_2022_2\", \"NAICS_2022_3\", \"NAICS_2022_4\", \"NAICS_2022_5\", \"NAICS_2022_6\",\n                           \"MSA\", \"MSA_NAME\"]\ndf_cleaned = df.drop(*cols_to_drop)\n#df_cleaned.show(5, truncate = False)\n\n\n\n\nCode\n# Listing data types of the cleaned DataFrame\n#df_cleaned.dtypes\n\n\n\n\nCode\n# Converting spark dataframe to SQL table to have subsets for Machine Learning positions.\ndf_cleaned.createOrReplaceTempView(\"job_postings_data\")\n\nml_data_df = spark.sql(\"\"\"\n                            SELECT *\n                            FROM job_postings_data\n                            WHERE SALARY IS NOT NULL\n                            AND SALARY &gt; 0\n                            AND TITLE_CLEAN LIKE '%machine learning%';\n                            \"\"\")\nml_data_pd = ml_data_df.toPandas()\n#ml_data_pd.info()\n\n\n25/06/30 00:24:14 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n[Stage 2:&gt;                                                          (0 + 1) / 1]                                                                                \n\n\n\n\nCode\nml_data_df.select(\"TITLE_CLEAN\").distinct().show(10, truncate=False)\n\n\n[Stage 3:&gt;                                                          (0 + 1) / 1]                                                                                \n\n\n+---------------------------------------------------------------------------------------------------------------------------------+\n|TITLE_CLEAN                                                                                                                      |\n+---------------------------------------------------------------------------------------------------------------------------------+\n|enterprise artificial intelligence machine learning ai ml platform product manager senior lead data product management consultant|\n+---------------------------------------------------------------------------------------------------------------------------------+\n\n\n\nML specific positions are limited in title clean - Since we cannot seem to distinguish the data between Data Science and Machine Learning, from the dataset using job titles, we will focus on Data Scientist and Business Analyst positions. Qualitative data also suggested a strong overlap between Data Science and Machine Learning positions because the current job market expects candidates for Data scientist positions to have skills in not just ML models but production deployment and Artificial intelligence as well. (Nobrega, 2024)\n\n\nCode\n# Subsetting the main dataframe for Business Analyst, Data Analyst and Business Intelligence positions.\n\nba_da_data_df = spark.sql(\"\"\"\n                         SELECT *\n                         FROM job_postings_data\n                            WHERE SALARY IS NOT NULL\n                            AND SALARY &gt; 0\n                            AND LOT_SPECIALIZED_OCCUPATION_NAME IN ('Business Intelligence Analyst',\n                              'Business Analyst (General)', 'Data Analyst');\n\"\"\")\n\nba_da_data_pd = ba_da_data_df.toPandas()\n\n\n\n\nCode\n# Subsetting the main dataframe for Data Science positions.\nds_data_df = spark.sql(\"\"\"\n                      SELECT *\n                      FROM job_postings_data\n                        WHERE SALARY IS NOT NULL\n                        AND SALARY &gt; 0\n                        AND SOC_2021_5_NAME = 'Data Scientists';\n\"\"\")\nds_data_pd = ds_data_df.toPandas()\n\n\n\n\nCode\n# Condensing both dataframes to remove additional unncessary columns.\nba_da_cols_to_drop = ['ONET_NAME', 'SOC_2021_2_NAME', 'SOC_2021_3_NAME', 'SOC_2021_4_NAME',\n       'SOC_2021_5_NAME', 'LOT_CAREER_AREA_NAME', 'LOT_OCCUPATION_NAME','LOT_V6_SPECIALIZED_OCCUPATION_NAME',\n       'LOT_V6_OCCUPATION_NAME', 'NAICS_2022_4_NAME', 'NAICS_2022_3_NAME', 'NAICS_2022_5_NAME', 'NAICS_2022_6_NAME',  'MAX_YEARS_EXPERIENCE', 'MAX_EDULEVELS_NAME']\nba_da_data_pd = ba_da_data_pd.drop(columns=ba_da_cols_to_drop, axis=1) \n#ba_da_data_pd.info()\n\n\n\n\nCode\n# Removing job postings with no titles and min years of experience\nba_da_data_pd = ba_da_data_pd.dropna(subset = ['TITLE_CLEAN'])\nba_da_data_pd = ba_da_data_pd.dropna(subset = ['MIN_YEARS_EXPERIENCE'])\n#ba_da_data_pd.info()\n\n\n\n\nCode\nds_data_cols_to_drop = ['ONET_NAME', 'SOC_2021_2_NAME', 'SOC_2021_3_NAME', 'SOC_2021_4_NAME','LOT_CAREER_AREA_NAME', \n                        'LOT_OCCUPATION_NAME','LOT_SPECIALIZED_OCCUPATION_NAME', 'LOT_V6_SPECIALIZED_OCCUPATION_NAME',\n                        'LOT_V6_OCCUPATION_NAME', 'NAICS_2022_4_NAME', 'NAICS_2022_3_NAME','NAICS_2022_5_NAME', 'NAICS_2022_6_NAME',\n                        'MAX_YEARS_EXPERIENCE', 'MAX_EDULEVELS_NAME']\nds_data_pd = ds_data_pd.drop(columns=ds_data_cols_to_drop, axis=1) \n#ds_data_pd.info() \n\n\n\n\nCode\n# Removing job postings with no titles and min years of experience\nds_data_pd = ds_data_pd.dropna(subset = ['TITLE_CLEAN'])\nds_data_pd = ds_data_pd.dropna(subset = ['MIN_YEARS_EXPERIENCE'])\n#ds_data_pd.info()\n\n\n\n\nCode\n# Sorting categories under remote type name for both dataframes\nba_da_data_pd['REMOTE_TYPE_NAME'].unique()\nba_da_data_pd['REMOTE_TYPE'] = ba_da_data_pd['REMOTE_TYPE_NAME'].replace({\n    '[None]': 'Onsite',\n    'Not Remote': 'Onsite',\n    'Hybrid Remote': 'Hybrid',\n    'Remote': 'Remote'\n}).astype('category')\n\nds_data_pd['REMOTE_TYPE_NAME'] = ds_data_pd['REMOTE_TYPE_NAME'].replace({\n    '[None]': 'Onsite',\n    'Not Remote': 'Onsite',\n    'Hybrid Remote': 'Hybrid',\n    'Remote': 'Remote'\n}).astype('category')\n\n# Sorting categories under employment type name for both dataframes\nba_da_data_pd['EMPLOYMENT_TYPE_NAME'].astype('category')\nds_data_pd['EMPLOYMENT_TYPE_NAME'].astype('category')\n\n\n\n\nCode\n#ba_da_data_pd['EDUCATION_LEVELS_NAME'].unique()\n\n\n\n\nCode\n# Converting education levels into 2 categories Bachelor's or lower and Master's or PhD\nimport ast # Using ast.literal_eval to first convert stringified lists into python lists \nimport re # Need to remove those extra spaces in the Masters degree for proper classification\n\ndef clean_text(text):\n    text = text.replace(\"\\n\", \" \") \n    text = re.sub(r\"0\\s+\", \" \", text)  # Replacing those multiple spaces with single space for Masters degree\n    return text.strip()\n\n\ndef classify_education_level(edu_levels):\n    try:\n        levels = ast.literal_eval(edu_levels)\n\n        levels = [clean_text(level) for level in levels] \n\n        # defining categories now \n        Bachelors_or_lower = {\"Bachelor's degree\", \"Associate degree\", \"No Education Listed\", \"High school or GED\"}\n        Masters_or_PhD = {\"Master's degree\", \"Ph.D. or professional degree\"}\n\n        # Now applying IF logic\n        if any(level in Bachelors_or_lower for level in levels):\n            return \"Bachelors_or_lower\"\n        elif any(level in Masters_or_PhD for level in levels):\n            return \"Masters_or_PhD\"\n        else:\n            return \"Other\"\n    except:\n        return \"Unknown\"\n\n # Now we apply it to both dataframes \nba_da_data_pd['EDUCATION_LEVELS'] = ba_da_data_pd['EDUCATION_LEVELS_NAME'].apply(classify_education_level).astype('category')\nds_data_pd['EDUCATION_LEVELS'] = ds_data_pd['EDUCATION_LEVELS_NAME'].apply(classify_education_level).astype('category')\n\n\n\n\nCode\n#ba_da_data_pd['EDUCATION_LEVELS'].unique()\n#ds_data_pd['EDUCATION_LEVELS'].unique()\n\n\n\n\nCode\n# Separating Longitude and Latitude from the location column for maps visualization\ndef extract_lat_long(location):\n    try:\n        loc_dict = ast.literal_eval(location.replace(\"\\n\", \" \").strip())\n        return pd.Series([loc_dict.get(\"lat\"), loc_dict.get(\"lon\")])\n    except:\n        return pd.Series([None, None])\n    \nba_da_data_pd[['LATITUDE', 'LONGITUDE']] = ba_da_data_pd['LOCATION'].apply(extract_lat_long)\nds_data_pd[['LATITUDE', 'LONGITUDE']] = ds_data_pd['LOCATION'].apply(extract_lat_long)\n\n\n\n\nCode\n#ba_da_data_pd[[\"LONGITUDE\", \"LATITUDE\"]].head(5)\n\n\n\n\nCode\nba_da_data_pd.drop(columns=['REMOTE_TYPE_NAME', 'EDUCATION_LEVELS_NAME', \n                            'LOCATION'], axis = 1, inplace = True)\nds_data_pd.drop(columns=['REMOTE_TYPE_NAME', 'EDUCATION_LEVELS_NAME',\n                        'LOCATION'], axis = 1, inplace = True)\n\n\nSummarizing the cleaning of data for both positions: The most important data cleaning steps performed here were slicing the data for each position to process them individually. Location column was separated into Latitude and Logitude to enable geographic analysis of job postings. Remote type, education levels and employment type columns were converted into categories to visualized summarized data. Skillsets columns will be cleaned at a later stage when we analyze top skills for each position and then progress into Machine Learning.\n\n\n12 Geographical analysis of Business Analytics, Data Science and Machine Learning\n\n\nCode\n# Since the data is ready we can now create comparison bar plots \n# Top 10 states with highest number of job postings for Business Analyst, Data Analyst and Data Scientist positions\nimport hvplot.pandas\n\nba_da_state_counts = (ba_da_data_pd.groupby(['STATE_NAME', 'EDUCATION_LEVELS']).size().reset_index(name='COUNT'))\nds_state_counts = (ds_data_pd.groupby(['STATE_NAME', 'EDUCATION_LEVELS']).size().reset_index(name='COUNT'))\n\ntop_states_da = (ba_da_state_counts.groupby('STATE_NAME')['COUNT'].sum().nlargest(10).index)\nba_da_top10 = (ba_da_state_counts[ba_da_state_counts['STATE_NAME'].isin(top_states_da)]).sort_values(by='COUNT', ascending=False)  \n\ntop_states_ds = (ds_state_counts.groupby('STATE_NAME')['COUNT'].sum().nlargest(10).index)\nds_top10 = (ds_state_counts[ds_state_counts['STATE_NAME'].isin(top_states_ds)]).sort_values(by='COUNT', ascending=False)\n\n# Plotting stacked bar plots \nba_da_plot = ba_da_top10.hvplot.bar(x='STATE_NAME', y='COUNT', by='EDUCATION_LEVELS', stacked=True, \n                        title='Top 10 States for BA and DA Positions',rot = 45,\n                        xlabel='States', ylabel='Number of Job Postings', width=500, height=400)    \nds_plot = ds_top10.hvplot.bar(x='STATE_NAME', y='COUNT', by='EDUCATION_LEVELS', stacked=True,\n                    title='Top 10 States for Data Scientist Positions',rot = 45,\n                    xlabel='States', ylabel='Number of Job Postings', width=500, height=400)\ncombined_plot = (ba_da_plot + ds_plot).opts(shared_axes=False)\ncombined_plot\n\n# Saving the plot for HTML rendering\nfrom holoviews import save\nhvplot.save(combined_plot, \"./visualizations/top_states_job_postings.html\") \n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\nCode\n#combined_plot\n\n\nAnalysis - Our first step in laying our career path is to narrow down the geographical locations where the positions are frequently available, so we have better chance of landing a job. Higher the number of positions available in a location, higher the chances of landing a job even though the competition is high, the odds of receiving an offer remain optimistic. The above plot is an hvplot providing a side by side comparison of top 10 states in the US for Business Analyst/Data Analyst and Data Scientist positions. The data is aggregated by the number of positions available in each state. The plot shows that California, Texas, New York, and Florida are the top states for both positions, with California having the highest number of positions available. This is expected as these states have high concentrations of technology companies and startups, which are the primary employers of data professionals. To add a layer of granularity, we can see that very few positions focus on education levels for both positions. However, Data scientist positions generally demand for a Masters or PhD degree alongwith a strong experience in analytics and expertise in ML models. Surprisingly, Massachusetts does not fall in the top 10 states which is our preferred state but with current labor market these initial signs suggest that relocation should be considered to keep enough options open.\n\n\nCode\n# Geospatial analysis of top 10 industries that have BA/DA positions\nba_da_ind_counts = (ba_da_data_pd.groupby(\"NAICS_2022_2_NAME\").size().reset_index(name = \"COUNT\").sort_values(by = \"COUNT\", \n                                                                                                              ascending = False).head(10))\n\nba_da_filtered = ba_da_data_pd[ba_da_data_pd[\"NAICS_2022_2_NAME\"].isin(ba_da_ind_counts[\"NAICS_2022_2_NAME\"])]\nba_da_filtered = ba_da_filtered[(ba_da_filtered[\"LATITUDE\"] != 0) & (ba_da_filtered[\"LONGITUDE\"] != 0)]\n\n\nba_da_map = ba_da_filtered.hvplot.points(\"LONGITUDE\", y = \"LATITUDE\", geo = True, \n                                         tiles = True, c = \"NAICS_2022_2_NAME\", colorbar = False,\n                                         hover_cols = [\"NAICS_2022_2_NAME\", \"CITY_NAME\", \"STATE_NAME\", \"SALARY\"],\n                                         title = 'Top 10 Industries hiring for BA/DA positions',\n                                         width = 800, height = 500, xlim = (-130, -65), ylim = (24,50)).opts(\n                                             legend_position = \"bottom_left\", legend_opts = {'label_text_font_size': '5pt',\n                                             'title_text_font_size': '4pt'})\nhvplot.save(ba_da_map, \"./visualizations/ba_da_indgeomap.html\")                             \n#ba_da_map\n\n\n\n\n\nAnalysis - We first identified our preferred industry and those were Marketing (Unclassified industry), Healthcare and Finance. By plotting the job postings for both BA/DA and Data Scientist positions, we looked at which states have high postings for these industries. The above plot is specifically for BA/DA jobs, we can see that along the east cost these industries are more prominent, specially in NYC, Boston, Philadelphia and Washington. When we move to the west, the tight cluster as expected is around LA and San Jose in California. Finance industry is more prominent on the east likely because of the presence of Wall street in NYC.\n\n\nCode\n# Geospatial analysis of top 10 industries that have Data scientist positions\nds_ind_counts = (ds_data_pd.groupby(\"NAICS_2022_2_NAME\").size().reset_index(name = \"COUNT\").sort_values(by = \"COUNT\", \n                                                                                                              ascending = False).head(10))\n\nds_filtered = ds_data_pd[ds_data_pd[\"NAICS_2022_2_NAME\"].isin(ds_ind_counts[\"NAICS_2022_2_NAME\"])]\nds_filtered = ds_filtered[(ds_filtered[\"LATITUDE\"] != 0) & (ds_filtered[\"LONGITUDE\"] != 0)]\n\n\nds_map = ds_filtered.hvplot.points(\"LONGITUDE\", y = \"LATITUDE\", geo = True, \n                                         tiles = True, c = \"NAICS_2022_2_NAME\", colorbar = False,\n                                         hover_cols = [\"NAICS_2022_2_NAME\", \"CITY_NAME\", \"STATE_NAME\", \"SALARY\"],\n                                         title = 'Top 10 Industries hiring for BA/DA positions',\n                                         width = 800, height = 500, xlim = (-130, -65), ylim = (24,50)).opts(\n                                             legend_position = \"bottom_left\", legend_opts = {'label_text_font_size': '5pt',\n                                            'title_text_font_size': '4pt'})\nhvplot.save(ds_map, \"./visualizations/ds_indgeomap.html\")   \n                                \n#ds_map\n\n\n\n\n\nAnalysis- This plot focuses on the Data Science positions and it is evident that the number of jobs are considerably higher for this position regardless of the industry. The trend is similar to BA/DA positions in terms of clustering around east cost states and on the west coast in Sacramento, CA and San Jose. However, surprisingly for us Seattle has dense cluster for Healtcare and North Carolina and Chicago seem to have a big cluster for Marketing (Unclassified industry)\n\n\n13 Salary Comparison & Trends across both positions\n\n\nCode\n# Combining both dataframes to create overlayed histograms \nba_da_data_pd[\"ROLE\"] = \"BA/DA\"\nds_data_pd[\"ROLE\"] = \"Data Scientist\"\ncombined_df = pd.concat([ba_da_data_pd, ds_data_pd])\n\ncombined_hist = px.histogram(combined_df, x = \"SALARY\", color = \"ROLE\", \n                             nbins = 50, barmode = \"overlay\", histnorm = \"probability density\",\n                             title = \"Salary distributions for BA/DA and Data Scientists\",\n                             marginal = \"violin\")\ncombined_hist.update_traces(opacity = 0.75)\n\nimport kaleido\ncombined_hist.write_html(\"./visualizations/salary_distribution.html\")\ncombined_hist.write_image(\"./visualizations/salary_distribution.png\")\n\n#combined_hist.show()\n\n\n\n\n\nSalary distribution analysis: We have now moved to the monetary value offered by both positions and we already know that data science being the senior position commands higher salary but the purpose of this plot is to identify what is the sweet spot of the salary range where both positions lie in 2024. The peak for BA/DA positoions is between $80K-$100K. We can also see from the overlay plot that the violin plot starts to shrink immediately after $100K and the right tail is light compared to Data science positions. For Data Scientist the median salary is $120K and the upper fence is almost $240K with much heavier right tails which is likely influenced by the information sector where salaries for this position can be as good as senior software developer position.\n\n\nCode\n# Salary distribution and employment type (Faceted)\ntop10_ba_da_inds = ba_da_data_pd['NAICS_2022_2_NAME'].value_counts().nlargest(10).index\ntop10_ds_inds = ds_data_pd['NAICS_2022_2_NAME'].value_counts().nlargest(10).index\n\n# Filtering datasets to include only top 10 industries to keep it consistent with other plots\nba_da_filt1 = ba_da_data_pd[ba_da_data_pd['NAICS_2022_2_NAME'].isin(top10_ba_da_inds)]\nds_filt1 = ds_data_pd[ds_data_pd['NAICS_2022_2_NAME'].isin(top10_ds_inds)]\n\nimport plotly.graph_objects as go\n\n# Create BA/DA box plot with industry in legend and employment type as facets\nba_da_emp_ind = px.box(\n    ba_da_filt1, \n    y='SALARY',  \n    x='EMPLOYMENT_TYPE_NAME',             \n    color='NAICS_2022_2_NAME', \n    height=700,\n    width=1000)\n\n# Data Scientist plot\nds_emp_ind = px.box(\n    ds_filt1, \n    y='SALARY',\n    x='EMPLOYMENT_TYPE_NAME',\n    color='NAICS_2022_2_NAME',\n    height=700,\n    width=1000)\nimport plotly.graph_objects as go\ndist_fig = go.Figure()\n\nfor trace in ba_da_emp_ind.data:\n    trace.visible = True\n    dist_fig.add_trace(trace)\nfor trace in ds_emp_ind.data:\n    trace.visible = False  \n    dist_fig.add_trace(trace)\n\nn_ba_da = len(ba_da_emp_ind.data)\nn_ds = len(ds_emp_ind.data)\n\ndropdown_buttons = [\n    dict(label=\"BA/DA\",\n         method=\"update\",\n         args=[{\"visible\": [i &lt; n_ba_da for i in range(n_ba_da + n_ds)]},\n               {\"title\": \"BA/DA Salary Distribution by Employment Type and Industry (Top 10)\"}]),\n\n    dict(label=\"Data Scientist\",\n         method=\"update\",\n         args=[{\"visible\": [i &gt;= n_ba_da for i in range(n_ba_da + n_ds)]},\n               {\"title\": \"Data Scientist Salary Distribution by Employment Type and Industry (Top 10)\"}])\n]\n\n# Update layout with dropdown\ndist_fig.update_layout(\n    updatemenus=[dict(\n        buttons=dropdown_buttons,\n        direction=\"down\",\n        showactive=True,\n        x=0.5,\n        xanchor=\"center\",\n        y=1.15,\n        yanchor=\"top\"\n    )],\n    xaxis_title=\"Employment Type\",\n    yaxis_title=\"Salary\",\n    legend_title=\"Industry\",\n    height=700,\n    width=1000,\n    boxmode=\"group\"\n)\ndist_fig.write_html(\"./visualizations/salary_dist_emp_ind.html\")\ndist_fig.write_image(\"./visualizations/salary_dist_emp_ind.png\")\n\n#dist_fig.show()\n\n\n\n\n\nSalary distribution by Industry - In the previous plot, we compared salaries at the highest level, in this case we are being more specific to industries we are interested in (Unclassified for Marketing, Finance and Health care). For BA/DA positions we can see that Finance sector appears to be more lucrative compared to unclassified and Healthcare. Median salary for full time BA/DA role is $112K whereas for Marketing and Healthcare it is close to $95K which seems to be okay for full time positions but the range does fall as low as $40K which could be for junior or entry level positions which is worrisome specially for us as international students as there is benchmark for H1b approval in terms of salaries. In terms of Data Science, all the 3 industries are very lucrative as the average salary is well above $120K and can go as high as $220K. Finance and Insurance in this case display more rapid growth.\n\n\n14 Skills Trends Analysis across Business Analyst/Data Analyst and Data Scientist positions\n\n\nCode\n# Cleaning skills column to get them as list for each row and continue with analysis \ndef clean_skills_column(df, col):\n    df[col] = df[col].apply(lambda x: ast.literal_eval(x) if pd.notnull(x) else [])\n    df[col] = df[col].apply(lambda lst: [i.strip().replace(\"\\n\", \"\") for i in lst])\n    return df\n\nskill_cols = ['COMMON_SKILLS_NAME', 'SOFTWARE_SKILLS_NAME', 'SPECIALIZED_SKILLS_NAME']\n\nfor col in skill_cols:\n    ba_da_data_pd = clean_skills_column(ba_da_data_pd, col)\n    ds_data_pd = clean_skills_column(ds_data_pd, col)\n\n\n\n\nCode\n# Our thought process is to visualize first the top 10 skills for each role and based on how many times they appear \n# Respective job postings and then get granular\ndef process_skills(df, role, skill_col):\n    temp = df[['NAICS_2022_2_NAME', 'SALARY', skill_col]].copy()\n    temp['ROLE'] = role\n    temp = temp.rename(columns={skill_col: 'SKILLS', 'NAICS_2022_2_NAME': 'INDUSTRY'})\n    temp = temp.explode('SKILLS')\n    temp = temp.dropna(subset=['SKILLS'])\n    temp['SKILL_TYPE'] = skill_col.replace('_NAME', '').title().replace('_', ' ')\n    return temp.rename(columns={'SKILLS': 'SKILL'})\n\nskill_data = []\nfor col in skill_cols:\n    skill_data.append(process_skills(ba_da_data_pd, 'BA/DA', col))\n    skill_data.append(process_skills(ds_data_pd, 'Data Scientist', col))\n\nall_skills = pd.concat(skill_data, ignore_index=True)\n\n\n\n\nCode\nba_da_top_skills = {}\nds_top_skills = {}\n\nroles_data = {\n    'BA/DA': all_skills[all_skills['ROLE'] == 'BA/DA'],\n    'Data Scientist': all_skills[all_skills['ROLE'] == 'Data Scientist']\n}\n\nfor role, role_df in roles_data.items():\n    skill_type_dict = {}\n    for skill_type in role_df['SKILL_TYPE'].unique():\n        temp_df = role_df[role_df['SKILL_TYPE'] == skill_type]\n        top_10_series= (\n            temp_df['SKILL']\n            .value_counts()\n            .nlargest(10)\n        )\n        top_10_df = top_10_series.reset_index()\n        top_10_df.columns = ['SKILL', 'COUNT']\n        skill_type_dict[skill_type] = top_10_df\n    \n    if role == 'BA/DA':\n        ba_da_top_skills = skill_type_dict\n    else:\n        ds_top_skills = skill_type_dict\n\n\n\n\nCode\nimport plotly.graph_objects as go\n\ndef create_bubble_chart(role_name, role_data):\n    skill_bubble = go.Figure()\n    buttons = []\n    trace_count = 0\n    \n    for i, (skill_type, df) in enumerate(role_data.items()):\n        visible = [False] * len(role_data)\n        visible[i] = True  # show only the selected skill type initially\n        \n        skill_bubble.add_trace(go.Scatter(\n            x=df['SKILL'],\n            y=df['COUNT'],\n            mode='markers+text',\n            text=df['SKILL'],\n            textposition='top center',\n            textfont= dict(size = 7),\n            marker=dict(\n                size=df['COUNT'],\n                sizemode='area',\n                sizeref=2. * df['COUNT'].max() / (40. ** 2),\n                sizemin=10\n            ),\n            name=skill_type,\n            visible=True if i == 0 else False\n        ))\n\n        buttons.append(dict(\n            label=skill_type,\n            method='update',\n            args=[\n                {'visible': [j == i for j in range(len(role_data))]},\n                {'title': f\"{role_name} - {skill_type}\"}\n            ]\n        ))\n\n    skill_bubble.update_layout(\n        title=f\"{role_name} - {list(role_data.keys())[0]}\",\n        updatemenus=[dict(\n            buttons=buttons,\n            direction=\"down\",\n            showactive=True,\n            x=0.1,\n            y=1.15\n        )],\n        xaxis_title=\"Skill\",\n        yaxis_title=\"Count\",\n        height=600\n    )\n\n    return skill_bubble\n\n# Create and display\nskill_bubble_ba_da = create_bubble_chart(\"BA/DA\", ba_da_top_skills)\nskill_bubble_ds = create_bubble_chart(\"Data Scientist\", ds_top_skills)\n\nskill_bubble_ba_da.write_html(\"./visualizations/skill_bubble_ba.html\")\nskill_bubble_ba_da.write_image(\"./visualizations/skill_bubble_ba.png\")\nskill_bubble_ds.write_html(\"./visualizations/skill_bubble_ds.html\")\nskill_bubble_ds.write_image(\"./visualizations/skill_bubble_ds.png\")\n\n#skill_bubble_ba_da.show()\n#skill_bubble_ds.show()\n\n\n\n\n\n\n\n\nAnalysis Top 10 skills - The above plot highlights top 10 skills from each skill type (Common, Specialized and Software skills), this will give a full overview of what is required to be successful in the role and match the demands of the current labor market in these domains. In terms of common skills, we can see that common skills or so to say soft skills like communication, Management and Problem solving are in both roles but the presence is considerably higher in Data scientist. Communication as expected is at the highest because both these roles require high collaboration. Strangely for data scientist, the postings that require Python is less but that could also be because some postings have the tendency to include Python libraries instead of using the tool name because they are looking for specific candidates who should know these libraries. Computer Science seems to be one of the highest requirement for data science which can be influenced by the Information and Tech sector. On BA/DA roles, Dashboarding and Business Intelligence tools are on higher scale because that is what the role entails, there is consistent use of SQL and BI tools alongwith some use of Python.\n\n\nCode\n# Average Min years of experience required across Industries for BA/DA and Data Science positions\n\n# Calculating average experience (minimum) per industry for each role\navg_exp_by_industry_role = (\n    combined_df.groupby(['ROLE', 'NAICS_2022_2_NAME'])\n    .agg(AVG_MIN_EXPERIENCE=('MIN_YEARS_EXPERIENCE', 'mean'))\n    .reset_index()\n    .rename(columns={'NAICS_2022_2_NAME': 'INDUSTRY'})\n)\n\nba_df = avg_exp_by_industry_role[avg_exp_by_industry_role['ROLE'] == 'BA/DA'].sort_values(by='AVG_MIN_EXPERIENCE', ascending=False)\nds_df = avg_exp_by_industry_role[avg_exp_by_industry_role['ROLE'] == 'Data Scientist'].sort_values(by='AVG_MIN_EXPERIENCE', ascending=False)\n\nhbar_ba = px.bar(\n    ba_df,\n    x='AVG_MIN_EXPERIENCE',\n    y='INDUSTRY',\n    orientation='h',\n    title='Avg Min Years of Experience by Industry – BA/DA',\n    labels={'AVG_MIN_EXPERIENCE': 'Avg Min Experience', 'INDUSTRY': 'Industry'},\n    height=800\n)\nhbar_ba.update_layout(yaxis=dict(tickfont=dict(size=10)))\n\nhbar_ds = px.bar(\n    ds_df,\n    x='AVG_MIN_EXPERIENCE',\n    y='INDUSTRY',\n    orientation='h',\n    title='Avg Min Years of Experience by Industry – Data Scientist',\n    labels={'AVG_MIN_EXPERIENCE': 'Avg Min Experience', 'INDUSTRY': 'Industry'},\n    height=800\n)\n\nhbar_ds.update_layout(yaxis=dict(tickfont=dict(size=10)))\nhbar_ba.write_html(\"./visualizations/avg_exp_indba.html\")\nhbar_ba.write_image(\"./visualizations/avg_exp_indba.png\", width=1000, height=800, scale=2)\nhbar_ds.write_html(\"./visualizations/avg_exp_indds.html\")\nhbar_ds.write_image(\"./visualizations/avg_exp_indds.png\", width=1000, height=800, scale=2)\n\n#hbar_ba.show()\n#hbar_ds.show()\n\n\n\n\n\n\n\n\nAverage Experience by Industry Analysis - When it comes to skills analysis, it is not just if a candidate knows the skill but how much experience is required also is critical. As per (Pushpa Singh & Garg, 2024), he and his co-authors had explained that the industry at this point in time is valuing experience of using the skills on real-world data than just backing of academic projects. Hence, as we step into the job market in search of an ideal job it is critical to know what are the demands of the companies in our preferred industries (Healthcare, Marketing and Finance) in terms of the number of years of experience. Although the average minimum years experience for all these 3 industry groups is above 3, we can speculate this is likely caused because of some of the executive positions failling under these industries. However, it is important to note that even after removing those outliers we should be speculating something aroun 0-2 years range and that highlights the importance of collaborating on real-world projects, internships and putting in the work beyond the academics.\n\n\n15 Machine Learning: Random Forest for predicting Salary\n\n\nCode\n# Converting pandas dataframes back into spark \nba_da_data_df = spark.createDataFrame(ba_da_data_pd)\nds_data_df = spark.createDataFrame(ds_data_pd)\n\n# Keeping only common columns in both dataframes\ncols_ba = set(ba_da_data_df.columns)\ncols_ds = set(ds_data_df.columns)\n\ncommon_cols = list(cols_ba.intersection(cols_ds))\n\nml_ba_da_df = ba_da_data_df.select(common_cols)\nml_ds_data_df = ds_data_df.select(common_cols)\n\n# Combining both dataframes for ML\nml_combined_df = ml_ba_da_df.unionByName(ml_ds_data_df)\n\n\n\n\n16 Cleaning the target variable and features in the dataset: Feature Engineering\n\n\nCode\nfrom pyspark.sql.functions import col, pow\nfrom pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, CountVectorizer\nfrom pyspark.ml import Pipeline\n\n# Dropping rows with NA values in the columns that will be used in the model \nml_df = ml_combined_df.dropna(subset=[\"SALARY\", \"MIN_YEARS_EXPERIENCE\", \"SPECIALIZED_SKILLS_NAME\",\n                     \"EDUCATION_LEVELS\"])\n\n# Using CountVectorizer instead of OneHotencoder to convert list of skills into a sparse vector\ncv = CountVectorizer(inputCol=\"SPECIALIZED_SKILLS_NAME\", outputCol=\"SKILLS_VEC\", vocabSize = 1000, binary =True )\n\n# Encoding these categorical variables \nindexers = StringIndexer(inputCol =  \"EDUCATION_LEVELS\", outputCol = \"EDU_IDX\", handleInvalid = \"skip\")\n\n# Using vector assembler to assemble features (for GLR and Random forest)\nassembler = VectorAssembler(inputCols = [\"MIN_YEARS_EXPERIENCE\"] + [\"EDU_IDX\"] + [\"SKILLS_VEC\"],\n                                         outputCol = \"features\")\n# Building the pipeline of target and features \ncv_model = cv.fit(ml_df)\nml_df = cv_model.transform(ml_df)\n\nindexers_model = indexers.fit(ml_df)\nml_df = indexers_model.transform(ml_df)\n\ndata = assembler.transform(ml_df)\n\n# Displaying the final structure\ndata.select(\"SALARY\", \"features\").show(5, truncate = True)\n\n\nFeature Selection - For continuous variables I have used minimum experience required for a job posting because that will be an indicator for junior and more senior level roles as we have some executive roles as well. For categorical variables, we have selected specialized skills because those skills ideally set the salary, for eg if we know SQL plus AWS services and how to work with RDS then we might command higher salary then those that know SQL and Excel but no cloud knowledge. Also we used Vectorizer instead of one Hot encoding just to limit the number of features and keep the computation stable.\n\n\n17 Splitting the prepared data into Training and Test set\n\n\nCode\ntrain_data, test_data = data.randomSplit([0.8, 0.2], seed = 317)\nprint((train_data.count()), len(train_data.columns))\nprint((test_data.count()), len(test_data.columns))\n\n\n\n\nCode\n# Excecuting Random Forest Model\n\n\n\n\nCode\nfrom pyspark.ml.regression import RandomForestRegressor\n\n# Initiating the model\nrf = RandomForestRegressor(featuresCol = \"features\", labelCol = \"SALARY\", numTrees = 150, maxDepth = 6, seed = 317)\n\n# Training the Random Forest model\nrf_model = rf.fit(train_data.select(\"SALARY\", \"features\"))\n\n# Generating predictions\nrf_preds = rf_model.transform(train_data.select(\"SALARY\", \"features\"))\n\n\n\n\nCode\nskill_features = cv_model.vocabulary  # List of strings\nall_feature_names = [\"MIN_YEARS_EXPERIENCE\", \"EDU_IDX\"] + skill_features\n\nimportances = rf_model.featureImportances.toArray()\n\nfeature_df = pd.DataFrame({\n    \"Feature\": all_feature_names,\n    \"Importance\": importances\n}).sort_values(by=\"Importance\", ascending=False)\n\n\n\n\n18 Visualizing Feature Importance\n\n\nCode\ntop_n = 10\ntop_features = feature_df.head(top_n)\n\nplt.figure(figsize=(10, 8))\nplt.barh(top_features['Feature'], top_features['Importance'], color='skyblue')\nplt.xlabel(\"Feature Importance\")\nplt.title(f\"Top {top_n} Feature Importances from Random Forest\")\nplt.gca().invert_yaxis()\nplt.tight_layout()\nplt.savefig(\"./visualizations/rf_feature_importance.png\", dpi=300, bbox_inches='tight')\n\n#plt.show()\n\n\n\n\n\nTop 10 Rf imp\n\n\n\n\n19 Extracting evaluation metrics\n\n\nCode\nfrom pyspark.ml.evaluation import RegressionEvaluator\nevaluator = RegressionEvaluator(labelCol=\"SALARY\", predictionCol=\"prediction\")\n\nrmse = evaluator.setMetricName(\"rmse\").evaluate(rf_preds)\nr2 = evaluator.setMetricName(\"r2\").evaluate(rf_preds)\n\nmetrics_df = pd.DataFrame({\n    'Metric': ['Root Mean Squared Error (RMSE)', 'R² (Coefficient of Determination)'],\n    'Value': [round(rmse, 2), round(r2, 4)]\n})\nmetrics_df.to_csv(\"./data/rf_metrics_table.csv\")\nprint(metrics_df.to_string(index=False))\n\n\nndtnkxnth ./data/rf_metrics_table.csv\nRF Evaluation & Analysis - From extracting the feature importances we know that minimum years experience plays a strong driver in predicting salary, however in terms of others like Enterprise Architecture, Data analysis and MapReduce are specialized skills and since we are using both Business Analyst and Data Scientist job postings to train this it is hard to evaluate if this would affect the salaries of both the positions in the same way. Mostly Mapreduce and cloud architecture are not the skills that are expected from a data analyst so this is likely attributed to Data Scientist. From the results it seems it would have been better to train the model and then make predictions using it separately for both positions, this would have limited the number of features and would have made the model more streamlined. If we look at the RMSE of the model it is deviating $29.6K from the actual salary values while making predictions which is acceptable considering the real-world factors where only skill sets and experience alone won’t determine the final value of the salary. However, these are strong drivers and from the R2 value the model is doing much better than capturing the mean value of the salary in the data range, however we would better look at RMSE values and features context than R2 for picking a model.\n\n\n20 Conclusion\nSummarizing the analysis from the various processes that we conducted above, we can briefly conclude that the market is extremely competitive at this stage, even though we did not look at specific AI trends from skills perspective we know that it has pushed the standards in the market up for data analysts as well by some margin. SQL is the core of data analysis be it data scientist or analyst, this tool becomes the first access point to data and is essential to condense the data into smaller subsets relatively to process it further of ML experimentation or insights reporting through dashboards. From an experience standpoint, simply completing Masters with generalized projects won’t make the cut, there has to be specific strategic learning process to get ahead of the clutter in the labor market. Lastly, in terms of further analysis we could further group the skills into subsets and use some NLP techniques to capture what specific skills in an industry can be mapped to either of these positions and what is common irrespective of the vertical. Although we are able to make some general statements about this but interesting patterns could be discovered from this analysis.\n\n\n21 Xinyi Dong (Sheryl) Carrer plan\n\n\n\nSheryl’s career path\n\n\n\n\n22 Yao Ma (April) Career plan\n\n\n\nYao’s career path\n\n\n\n\n23 Hiten’s Career plan\n\n\n\nHiten’s career path\n\n\n\n\n24 Conclusion:\nEach of our plan is based on the industry requirements as well as our the way we have envisioned our career paths for 3-5 years down the line. One element however is common in all of the career paths, the specific steps chosen are driven by the conclusions from research and quantitative analysis that was conducted. We found that constant learning and willingness to attain expertise in more than one skills is what is in demand in the current labor market. However, with the advent of AI soft skills like critical thinking, creativity and unconventional approach to problem solving is more at the forefront and we are striving to inculcate that approach in our daily practice.\n\n\n\n\n\nReferences\n\nBhattacherjee, A., & Badhan, A. K. (2024). Convergence of data analytics, big data, and machine learning: Applications, challenges, and future direction. Springer Nature, 145, 317–334. https://doi.org/10.1007/978-981-97-0448-4_15\n\n\nBusiness Management & Research, A. I. of. (n.d., n.d.). The history of the evolution of business analytics. https://www.asmibmr.edu.in/blog/the-history-of-the-evolution-of-business-analytics\n\n\nForum, W. E. (2020). The future of jobs report 2020. World Economic Forum. https://www.weforum.org/publications/the-future-of-jobs-report-2020\n\n\nHan, F., & Ren, J. (2024). Analyzing big data professionals: Cultivating holistic skills through university education and market demands. IEEE Xplore, 12, 23568–23577. https://doi.org/10.1109/ACCESS.2024.3363876\n\n\nJin Liu, K. C., & Lyu, W. (2024). Embracing artificial intelligence in the labour market: The case of statistics. Humanities and Social Sciences Communications, 11(1). https://doi.org/10.1057/s41599-024-03557-6\n\n\nLabor Statistics, U. S. B. of. (2024). Data scientists — occupational outlook handbook. https://www.bls.gov/ooh/math/data-scientists.htm\n\n\nLi, L. (2022). Reskilling and upskilling the future ready workforce for industry 4.0 and beyond. Information Systems Frontiers, 24(3), 1–16. https://doi.org/10.1007/s10796-022-10308-y\n\n\nNobrega, S. (2024). The 5 data science skills you can’t ignore in 2024. https://towardsdatascience.com/the-5-data-science-skills-you-cant-ignore-in-2024-ceba3ea7726c\n\n\nPushpa Singh, A. R. M., & Garg, P. (2024). Data analytics and machine learning: Navigating the big data landscape (Vol. 145). Springer Nature. https://doi.org/10.1007/978-981-97-0448-4\n\n\nShirani, A. (2016). Identifying data science and analytics competencies based on industry demand. Issues in Information Systems, 17(IV), 137–144. https://doi.org/10.48009/4_iis_2016_137-144\n\n\nYugal, L. (2022). Business analytics: Trends and challenges. International Conference on Intelligent Emerging Methods of Artificial Intelligence & Cloud Computing, 273, 236–243. https://doi.org/10.1007/978-3-030-92905-3_31"
  },
  {
    "objectID": "career_plan_reco.html",
    "href": "career_plan_reco.html",
    "title": "Individual Career Strategy based on Research and Quantitative analysis",
    "section": "",
    "text": "1 Xinyi Dong (Sheryl) Carrer plan\n\n\n\nSheryl’s career path\n\n\n\n\n2 Yao Ma (April) Career plan\n\n\n\nYao’s career path\n\n\n\n\n3 Hiten’s Career plan\n\n\n\nHiten’s career path\n\n\n\n\n4 Conclusion:\nEach of our plan is based on the industry requirements as well as our the way we have envisioned our career paths for 3-5 years down the line. One element however is common in all of the career paths, the specific steps chosen are driven by the conclusions from research and quantitative analysis that was conducted. We found that constant learning and willingness to attain expertise in more than one skills is what is in demand in the current labor market. However, with the advent of AI soft skills like critical thinking, creativity and unconventional approach to problem solving is more at the forefront and we are striving to inculcate that approach in our daily practice."
  },
  {
    "objectID": "qualitative_research.html",
    "href": "qualitative_research.html",
    "title": "Qualitative Research on Business Analytics, Data Science and Machine Learning Trends",
    "section": "",
    "text": "Selection Rationale:\nWe are at the early stages of our careers in the data analytics field, and as we look to pursue opportunities in the current, rapidly evolving U.S. market—specifically for data or business analysts—our priority is to focus on the critical requirements of data roles that help us fill any existing gaps in our skill set. Hence, we will conduct a qualitative deep dive into trends and recent changes in the analytics, data science, and machine learning domain before proceeding to verify whether this qualitative analysis is supported by the quantitative assessment of the Lightcast job posting data we have at hand.\nAlso, it is important to note that most data analytics principles can be applied to business analytics, as the two roles have a high degree of overlap. The former involves cleaning and processing data, while the latter (business analytics) takes those insights further and translates them into business decisions or improvements in policies, processes, or operations. In essence, data analytics focuses on the “what” and “why” from data, while business analytics goes further into developing the “how” and “what next” by leveraging those insights. (Jin Liu & Lyu, 2024)\n\n\nIntroduction:\nThis is a brief overview of how the convergence of Data analytics, Big Data and Machine Learning has become an influential force in every business that relies on data-driven decision-making. It also covers how Industry 4.0 is revolutionizing the manufacturing as well as service processes all over the world. In simple words, Industry 4.0 is an amalgamation of multiple disciplines like Internet of Things (IoT), Industrial Internet of Things (IIoT), artificial intelligence, machine learning, hyper convergent Infrastructure, deep learning and virtualization, all these create a strong and intelligent production system for businesses that enable them to carve insights from heaps of data that they are collecting but at the same time translate them into actionable items that are strongly backed. (Li, 2022). The review then shift focus on the importance of reskilling and/or upskilling is critical to be part of the talent that realizes Industry 4.0 to realize its full potential.\nThe World Economic Forum projected that half of all employees worldwide would need to reskilling by 2025 in its future jobs report 2020. (Forum, 2020). Life-long learning is not a choice but a norm in 2025 with the advent of AI, advanced applications of machine learning and increase uncertainty around ability of AI to replace candidates with jobs that have tasks that have potential to be automated.\nThe top 10 skills comparison from 2015, 2020 to 2025: \nIn context of Data science and machine learning, these are most sought soft skills in 2025, however industry reports reveal that there is shortage of big data client in the field and companies prefer candidates that possess one to three years of experience because they can quickly adapt to changing industry needs and help companies realize their full potential backed by big data processing and analysis. (Yugal, 2022) The literature review delves into details of each domain, explaining how they have evolved and what is required for success in this fast-evolving tech space.\n\n\nMachine Learning Trends:\nAs the digital era continues to push the envelope of transformation, the trifecta or the combination of Data Analytics, Big Data and Machine learning becomes a vital source for businesses to search practical insights and long-term advancement. This intersection has necessitated the need for new skill sets to effectively analyze and interpret complex, high-volume data. To understand the required skills in this domain, it is important to understand the full range of applications of ML. It ranges from decision-making processes, modeling layout form, identification of results from data analysis, and forecast for big data analytics-oriented programs.\nIn terms of industry specific applications, in life sciences ML is progressively used as a analytical and computational tool for study of vast unstructured data of genome libraries to set up automated workflows. Virtual assistants have been powered by ML-enabled speech recognition technology. In combination with ML, Deep learning has become a potent instrument in variety of sectors like audio and picture identification, natural language processing and even medicine (Bhattacherjee & Badhan, 2024). For these a sustainable talent training system is required, and it becomes the mission and responsibility of educational institutions as well as individual candidates to realize the full-scale potential of this domain. For instance, deep learning libraries like PyTorch, TensorFlow, Keras and MXNet have recently been developed and if these are introduced as conceptual content to students in advance, it will place a foundation of big data talents at the forefront and address the shortage of experienced and skilled talents that the business are looking for. (Han & Ren, 2024) A cluster analysis of Big Data expertise needs provided scores for various variables for each tool, algorithms and techniques. \n\n\nBusiness Analytics Trends:\nWith the advent of AI and digital governance evolving rapidly, the Business analytics field has expanded beyond just managerial outlook and expertise in the business process with some level of analysis. The emergence of Big Data has led to the involvement of Business analysts in statistical analysis as well as processing of vast amounts of data to generate insights. BA & intelligence teams can take those insights further to translate them into business process improvements, development of new practices by generating dashboards or written reports for stakeholders. (Yugal, 2022) \nBA & I involves a lot more techniques post 2023 that are implemented to structure a process of business decision-making. AI/ML integration, Cloud based analytics, and predictive analytics are at the forefront of this domain as volume of data is expanding rapidly and so as the cloud infrastructure adoption to execute analytics and forecast trends, customer behavior and understand market dynamics. (Business Management & Research, n.d.)\n\n\n\nBA techniques\n\n\n\n\nData Science Trends\nTo establish an understanding of this domain in simpler terms, one can say it is a step or few advanced to data analytics. It has high overlap with ML engineers and MLOps engineers and that makes sense in the real world as more and more companies expect their employees to have an understanding of a bit of everything because of the need of strong collaboration between these teams for each project.\nAbout 20,800 openings for data scientists are projected each year since 2024, on average over the decade. The growth of this space is expected to be 36% from 2023 to 2033, which is much faster than average of all the other occupations. (Labor Statistics, 2024)\nData science is more of an umbrella term that has been derived from industrial demand. The T-shaped configuration of skills is generally used to analyze the breadth of knowledge and skills required for a domain and to identify a functional area that one would like to gain expertise within that domain. The T-shape or π-shaped diagram for analytics is shown below: (Shirani, 2016) \nExploring the skillsets that have been dominant in data science roles across the board in recent years are below: ##Deep Learning: It is at the forefront of many in-demand frameworks right now, such as generative adversarial networks (GANs) and reinforcement learning which dive into artificial intelligence but as described in this entire review, each of these fields touch AI discipline in some form with data science and ML being closest to it. Sophisticated models like image classification, NLPs and anomaly detection use deep learning techniques and candidates who are looking to enter this space must have strong foundation of mathematical concepts (linear algebra, calculus, probability and statistics) and then should have understanding of core principles of deep learning – neural networks and backpropagation. (Nobrega, 2024)\n##Machine Learning Deployment: It is understood that experimenting various ML models on the data to capture patterns is a pre-requisite now, deploying the validated models in a production environment is crucial to derive business value. For this, candidates are required to have a strong grasp of fundamentals of ML, they should be familiar with one of the cloud platforms and should have understanding of deployment tools like Docker or Kubernetes. In addition to this, understanding of MLOps best practices and lifecycle management of ML models is also expected. Hence, it is clear that the role involves lifelong learning and hands on practice on the tools and to have all basics covered so that foundation for creativity can be laid when it comes to execution. (Nobrega, 2024)\n\n\nConclusion:\nIt is evident that in the past 2 years, each role deals with vast amount of data and hence understanding of cloud infrastructure and big data techniques is essential for success in these roles. Although, the expertise or level of skills in these disciplines may vary for each role but it is essential to have curiosity and willingness to upskill and reskill as per the evolving needs in the analytics domain and overall business requirements to stay relevant in the market.\n\n\n\n\n\n\n\n\nReferences\n\nBhattacherjee, A., & Badhan, A. K. (2024). Convergence of data analytics, big data, and machine learning: Applications, challenges, and future direction. Springer Nature, 145, 317–334. https://doi.org/10.1007/978-981-97-0448-4_15\n\n\nBusiness Management & Research, A. I. of. (n.d., n.d.). The history of the evolution of business analytics. https://www.asmibmr.edu.in/blog/the-history-of-the-evolution-of-business-analytics\n\n\nForum, W. E. (2020). The future of jobs report 2020. World Economic Forum. https://www.weforum.org/publications/the-future-of-jobs-report-2020\n\n\nHan, F., & Ren, J. (2024). Analyzing big data professionals: Cultivating holistic skills through university education and market demands. IEEE Xplore, 12, 23568–23577. https://doi.org/10.1109/ACCESS.2024.3363876\n\n\nJin Liu, K. C., & Lyu, W. (2024). Embracing artificial intelligence in the labour market: The case of statistics. Humanities and Social Sciences Communications, 11(1). https://doi.org/10.1057/s41599-024-03557-6\n\n\nLabor Statistics, U. S. B. of. (2024). Data scientists — occupational outlook handbook. https://www.bls.gov/ooh/math/data-scientists.htm\n\n\nLi, L. (2022). Reskilling and upskilling the future ready workforce for industry 4.0 and beyond. Information Systems Frontiers, 24(3), 1–16. https://doi.org/10.1007/s10796-022-10308-y\n\n\nNobrega, S. (2024). The 5 data science skills you can’t ignore in 2024. https://towardsdatascience.com/the-5-data-science-skills-you-cant-ignore-in-2024-ceba3ea7726c\n\n\nShirani, A. (2016). Identifying data science and analytics competencies based on industry demand. Issues in Information Systems, 17(IV), 137–144. https://doi.org/10.48009/4_iis_2016_137-144\n\n\nYugal, L. (2022). Business analytics: Trends and challenges. International Conference on Intelligent Emerging Methods of Artificial Intelligence & Cloud Computing, 273, 236–243. https://doi.org/10.1007/978-3-030-92905-3_31"
  }
]